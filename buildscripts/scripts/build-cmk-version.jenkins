import java.text.SimpleDateFormat

def DISTRO_LIST_DEFAULT = ''
def EDITION_DEFAULT = 'enterprise'
def NODE = ''
def DOCKER_TAG_DEFAULT
def USE_OMD_PACKAGE_CACHE_DEFAULT
withFolderProperties{
    if(JOB_BASE_NAME == 'nightly_build_containerized') {
        DISTRO_LIST_DEFAULT = env.DISTRO_LIST
        USE_OMD_PACKAGE_CACHE_DEFAULT = true
    } else {
        DISTRO_LIST_DEFAULT = env.DISTRO_LIST_TESTBUILD
        USE_OMD_PACKAGE_CACHE_DEFAULT = false
    }

    if(JOB_BASE_NAME == 'testbuild-cre') {
        EDITION_DEFAULT = 'raw'
    } else if(JOB_BASE_NAME == 'testbuild-cme') {
        EDITION_DEFAULT = 'managed'
    }

    NODE = env.BUILD_NODE
    DOCKER_TAG_DEFAULT = env.DOCKER_TAG_FOLDER
}

properties([
  buildDiscarder(logRotator(artifactDaysToKeepStr: '', artifactNumToKeepStr: '', daysToKeepStr: '7', numToKeepStr: '14')),
  parameters([
    string(name: 'DISTROS', defaultValue: DISTRO_LIST_DEFAULT, description: 'List of targeted distros' ),
    string(name: 'EDITION', defaultValue: EDITION_DEFAULT, description: 'Edition: raw, enterprise, free or managed' ),
    string(name: 'VERSION', defaultValue: 'daily', description: 'Version: "daily" for current state of the branch, e.g. "1.6.0b2" for building the git tag "v1.6.0b2".' ),
    string(name: 'DOCKER_TAG_BUILD', defaultValue: '', description: 'DOCKER_TAG_BUILD: Custom Docker Tag to use for this build. Leave empty for default' ),
    booleanParam(name: 'FAKE_WINDOWS_ARTIFACTS', defaultValue: false, description: 'Use faked windows agent artifacts instead of building them'),
    booleanParam(name: 'USE_OMD_PACKAGE_CACHE', defaultValue: USE_OMD_PACKAGE_CACHE_DEFAULT, description: 'Use OMD package cache (NEXUS_ environment variables needed)'),
    booleanParam(name: 'DEPLOY_TO_WEBSITE', defaultValue: false, description: 'Upload and deploy the packages to the website')
  ])
])

def PACKAGE_BUILDS = [:]
def AGENT_LIST = get_agent_list(EDITION)
def AGENT_BUILDS= [:]
def DISTRO_LIST = DISTROS.split(' ');

println("Building for the following Distros:" + DISTRO_LIST)
currentBuild.description = '\nBuilding for the following Distros:\n' + DISTRO_LIST + '\nFake artifacts: ' + FAKE_WINDOWS_ARTIFACTS

def DOCKER_BUILDS = [:]
// TODO: Change to versioning.get_branch and versioning.get_cmk_version! Then
// the copy&paste below can be removed.
def BRANCH = scm.branches[0].name.replaceAll("/","-")
def CMK_VERS = get_cmk_version(BRANCH, VERSION)
def BRANCH_VERSION

def OMD_ENV_VARS = ''
if (!params.USE_OMD_PACKAGE_CACHE) {
    // Testbuilds: Do not use our build cache to ensure we catch build related
    // issues. And disable python optimizations to execute the build faster
    OMD_ENV_VARS = ' NEXUS_BUILD_CACHE_URL="" PYTHON_ENABLE_OPTIMIZATIONS=""'
}

def DOCKER_ARGS = "--ulimit nofile=1024:1024"

def DOCKER_REGISTRY_NO_HTTP = ''
def SOURCE_DIR = ''
def DOCKER_GROUP_ID = ''

//
// MAIN
//

timeout(time: 12, unit: 'HOURS') {
    node(NODE) {
        SOURCE_DIR = WORKSPACE + "/git"

        cleanup_versions(WORKSPACE)

        stage('Checkout sources') {
            /// takes place as regular Jenkins user
            dir(SOURCE_DIR) {
                checkout_git(scm, VERSION)

                // Clean up left overs from previous runs, but keep previously
                // created virtual environments to save some time
                sh("make mrclean")

                // Load libraries
                versioning = load 'buildscripts/scripts/lib/versioning.groovy'
                windows = load 'buildscripts/scripts/lib/windows.groovy'
                str_mod = load 'buildscripts/scripts/lib/str_mod.groovy'
                notify = load 'buildscripts/scripts/lib/notify.groovy'
                upload_artifacts = load 'buildscripts/scripts/lib/upload_artifacts.groovy'
                docker_util = load 'buildscripts/scripts/lib/docker_util.groovy'

                docker.withRegistry(DOCKER_REGISTRY, 'nexus') {
                    def BUILD_IMAGE = docker.build("build-image:${env.BUILD_ID}", "--pull ${WORKSPACE}/git/buildscripts/docker_image_aliases/IMAGE_TESTING")
                    BUILD_IMAGE.inside(DOCKER_ARGS) {

                        withFolderProperties{
                            DOCKER_TAG = versioning.select_docker_tag(BRANCH, DOCKER_TAG_BUILD, DOCKER_TAG_DEFAULT)
                        }

                        versioning.patch_git_after_checkout(EDITION, CMK_VERS)
                        BRANCH_VERSION = versioning.get_branch_version()

                        DOCKER_REGISTRY_NO_HTTP = str_mod.strip_protocol_from_url(DOCKER_REGISTRY)
                    }

                    // Get the ID of the docker group from the node(!). This must not be
                    // executed inside the container (as long as the IDs are different)
                    DOCKER_GROUP_ID = docker_util.get_docker_group_id()
                }
            }
        }

        try {
            if (!params.FAKE_WINDOWS_ARTIFACTS) {
                // Clean up agent artifacts to not accidentally reuse things from
                // previous runs
                sh('rm -rf ${WORKSPACE}/agents/*')
                sh('mkdir -p ${WORKSPACE}/agents')

                AGENT_LIST.each { AGENT ->
                    AGENT_BUILDS['build agent ' + AGENT] = {
                        if (AGENT == 'windows') {
                            def FOLDER_ID = Jenkins.instance.getItemByFullName(currentBuild.fullProjectName).getParent().getFullName()
                            def WIN_PROJECT = "${FOLDER_ID}/windows-agent-build"
                            def WIN_PY_PROJECT = "${FOLDER_ID}/Windows-Python-Build"

                            def WIN_BUILD = build(job: WIN_PROJECT, parameters: [string(name: 'VERSION', value: VERSION)])
                            copyArtifacts(
                                projectName: WIN_PROJECT,
                                selector: specific(WIN_BUILD.getId()),
                                target: 'agents',
                                fingerprintArtifacts: true
                            )

                            def WIN_PY_BUILD = build(job: WIN_PY_PROJECT, parameters: [string(name: 'VERSION', value: VERSION)])
                            copyArtifacts(
                                projectName: WIN_PY_PROJECT,
                                selector: specific(WIN_PY_BUILD.getId()),
                                target: 'agents',
                                fingerprintArtifacts: true
                            )

                        }
                        else if (EDITION != 'raw') {
                            docker.withRegistry(DOCKER_REGISTRY, 'nexus') {
                                def BUILD_IMAGE = docker.build("build-${AGENT}-image:${env.BUILD_ID}", "--pull ${WORKSPACE}/git/buildscripts/docker_image_aliases/IMAGE_TESTING")
                                BUILD_IMAGE.inside(DOCKER_ARGS + " --group-add=${DOCKER_GROUP_ID} -v /var/run/docker.sock:/var/run/docker.sock") {
                                    build_linux_agent_updater(AGENT, EDITION, BRANCH_VERSION, DOCKER_REGISTRY_NO_HTTP)
                                }
                            }
                        }
                    }
                }
                parallel AGENT_BUILDS
            }
        } catch(Exception e) {
            notify.notify_error(e)
        }

        docker.withRegistry(DOCKER_REGISTRY, 'nexus') {
            create_and_upload_bom(WORKSPACE, BRANCH_VERSION, VERSION)

            def BUILD_IMAGE = docker.build("build-image:${env.BUILD_ID}", "--pull ${WORKSPACE}/git/buildscripts/docker_image_aliases/IMAGE_TESTING")
            BUILD_IMAGE.inside(DOCKER_ARGS) {
                create_source_package(WORKSPACE, CMK_VERS)

                def SOURCE_PACKAGE_NAME = get_source_package_name(WORKSPACE, EDITION, CMK_VERS)
                def BUILD_SOURCE_PACKAGE_PATH = SOURCE_DIR + "/" + SOURCE_PACKAGE_NAME
                def FINAL_SOURCE_PACKAGE_PATH = get_versions_dir(WORKSPACE, CMK_VERS) + "/" + SOURCE_PACKAGE_NAME

                copy_source_package(BUILD_SOURCE_PACKAGE_PATH, FINAL_SOURCE_PACKAGE_PATH)
                generate_version_file(get_versions_dir(WORKSPACE, CMK_VERS), CMK_VERS)

                cleanup_source_package(WORKSPACE, FINAL_SOURCE_PACKAGE_PATH)

                test_package(FINAL_SOURCE_PACKAGE_PATH, "source", WORKSPACE, SOURCE_DIR, CMK_VERS)

                upload_artifacts.upload(
                    NAME: "source",
                    FILE_PATH: FINAL_SOURCE_PACKAGE_PATH,
                    FILE_NAME: SOURCE_PACKAGE_NAME,
                    CMK_VERS: CMK_VERS,
                    UPLOAD_DEST: INTERNAL_DEPLOY_DEST,
                    PORT: INTERNAL_DEPLOY_PORT,
                )
            }
        }

        try {
            DISTRO_LIST.each { DISTRO ->
                PACKAGE_BUILDS[DISTRO] = {
                    // The following node call allocates a new workspace for each
                    // DISTRO.
                    //
                    // Note: Do it inside the first node block to ensure all distro
                    // workspaces start with a fresh one. Otherwise one of the node
                    // calls would reuse the workspace of the source package step.
                    //
                    // The DISTRO workspaces will then be initialized with the contents
                    // of the first workspace, which contains the prepared git repo.
                    node(NODE) {
                        docker.withRegistry(DOCKER_REGISTRY, 'nexus') {
                            def DISTRO_DIR = WORKSPACE + "/git"

                            docker.image(DISTRO + ':' + DOCKER_TAG).inside(DOCKER_ARGS + " -v ${SOURCE_DIR}:${SOURCE_DIR}:ro --hostname ${DISTRO}") {
                                cleanup_versions(WORKSPACE)
                                initialize_workspace(DISTRO, SOURCE_DIR, DISTRO_DIR)

                                withCredentials([usernamePassword(credentialsId: 'nexus', passwordVariable: 'NEXUS_PASSWORD', usernameVariable: 'NEXUS_USERNAME')]) {
                                    versioning.print_image_tag()
                                    build_package(DISTRO, OMD_ENV_VARS)
                                }
                            }

                            def BUILD_IMAGE = docker.build("build-image:${env.BUILD_ID}", "--pull ${WORKSPACE}/git/buildscripts/docker_image_aliases/IMAGE_TESTING")
                            BUILD_IMAGE.inside(DOCKER_ARGS + " -v ${SOURCE_DIR}:${SOURCE_DIR}:ro") {
                                def PACKAGE_NAME = get_package_name(WORKSPACE, DISTRO, CMK_VERS)
                                def BUILD_PACKAGE_PATH = DISTRO_DIR + "/" + PACKAGE_NAME
                                def FINAL_PACKAGE_PATH = get_versions_dir(WORKSPACE, CMK_VERS) + "/" + PACKAGE_NAME

                                sign_package(BUILD_PACKAGE_PATH, DISTRO, WORKSPACE)
                                test_package(BUILD_PACKAGE_PATH, DISTRO, WORKSPACE, SOURCE_DIR, CMK_VERS)
                                copy_package(BUILD_PACKAGE_PATH, DISTRO, FINAL_PACKAGE_PATH)

                                upload_artifacts.upload(
                                    NAME: DISTRO,
                                    FILE_PATH: FINAL_PACKAGE_PATH,
                                    FILE_NAME: PACKAGE_NAME,
                                    CMK_VERS: CMK_VERS,
                                    UPLOAD_DEST: INTERNAL_DEPLOY_DEST,
                                    PORT: INTERNAL_DEPLOY_PORT,
                                )

                            }
                        }
                        stage("clean distro workspace") {
                            cleanWs(cleanWhenFailure: false)
                        }
                    }
                }
            }
            parallel PACKAGE_BUILDS
        } catch(Exception e) {
            notify.notify_error(e)
        } finally {
            currentBuild.description = currentBuild.description + "<p><a href='${INTERNAL_DEPLOY_URL}/${CMK_VERS}'>Download Artifacts</a></p>"
            docker.withRegistry(DOCKER_REGISTRY, 'nexus') {
                def BUILD_IMAGE = docker.build("build-image:${env.BUILD_ID}", "--pull ${WORKSPACE}/git/buildscripts/docker_image_aliases/IMAGE_TESTING")
                BUILD_IMAGE.inside(DOCKER_ARGS) {
                    upload_artifacts.download_version_dir(INTERNAL_DEPLOY_DEST, INTERNAL_DEPLOY_PORT, CMK_VERS, get_versions_dir(WORKSPACE, CMK_VERS))
                    upload_artifacts.upload_version_dir(get_versions_dir(WORKSPACE, CMK_VERS), WEB_DEPLOY_DEST, WEB_DEPLOY_PORT)
                    if(params.DEPLOY_TO_WEBSITE) {
                        upload_artifacts.deploy_to_website(WEB_DEPLOY_URL, WEB_DEPLOY_PORT, CMK_VERS)
                    }
                }
            }
            stage("clean workspace") {
                cleanWs(cleanWhenFailure: false)
            }
        }
    }
}

//
// FUNCTIONS
//

def cleanup_versions(WORKSPACE) {
    stage('Prepare version directory') {
        sh('rm -rf "' + WORKSPACE + '/versions/"*')
        sh('mkdir -p "' + WORKSPACE + '/versions"')
    }
}

def get_versions_dir(WORKSPACE, CMK_VERS) {
    return WORKSPACE + "/versions/" + CMK_VERS
}

// Duplicate code with nightly-cmk-container.jenkins
def get_cmk_version(BRANCH, VERSION) {
    def DATE_FORMAT = new SimpleDateFormat("yyyy.MM.dd")
    def DATE = new Date()

    if (BRANCH == 'master' && VERSION == 'daily') {
        return DATE_FORMAT.format(DATE) // Regular daily build of master branch
    } else if (BRANCH.startsWith('sandbox') && VERSION == 'daily') {
        return DATE_FORMAT.format(DATE) + '-' + BRANCH // Experimental builds
    } else if (VERSION == 'daily') {
        return BRANCH + '-' + DATE_FORMAT.format(DATE) // version branch dailies (e.g. 1.6.0)
    } else {
        return VERSION
    }
}

def get_agent_list(EDITION) {
    if (EDITION == "raw") {
        return ["windows"]
    } else {
        return ["au-linux-64bit", "au-linux-32bit", "windows"]
    }
}

def checkout_git(scm, VERSION) {
    if (VERSION == 'daily') {
        checkout(scm)
    } else {
        checkout([
            $class: 'GitSCM',
            userRemoteConfigs: scm.userRemoteConfigs,
            branches: [
                [name: 'refs/tags/v' + VERSION]
            ]
        ])
    }
}

def build_linux_agent_updater(AGENT, EDITION, BRANCH_VERSION, DOCKER_REGISTRY_NO_HTTP) {
    stage('Build agent updater ' + AGENT) {
        def SUFFIX = ""
        if (AGENT == 'au-linux-32bit') {
            SUFFIX = '-32'
        }

        withCredentials([usernamePassword(credentialsId: 'nexus', passwordVariable: 'NEXUS_PASSWORD', usernameVariable: 'NEXUS_USERNAME')]) {
            sh script: """
                cd ${WORKSPACE}/git/enterprise/agents/plugins
                BRANCH_VERSION=${BRANCH_VERSION} DOCKER_REGISTRY_NO_HTTP=${DOCKER_REGISTRY_NO_HTTP} ./make-agent-updater${SUFFIX}
            """
        }
        sh """
            mkdir -p ${WORKSPACE}/agents
            cp ${WORKSPACE}/git/enterprise/agents/plugins/cmk-update-agent${SUFFIX} ${WORKSPACE}/agents
        """
    }
}

def generate_version_file(PATH, CMK_VERS) {
    sh("""
        echo "${CMK_VERS}" > ${PATH}/VERSION.cmk
    """)
}

def create_and_upload_bom(WORKSPACE, BRANCH_VERSION, VERSION) {
    def CMK_DIR = WORKSPACE + "/git"
    def SCANNER_DIR = WORKSPACE + "/dependencyscanner"
    def BOM_PATH = CMK_DIR + "/omd/bill-of-materials.json"
    def SCANNER_IMAGE

    stage('Prepare BOM') {
        dir(SCANNER_DIR) {
            checkout([
                $class: 'GitSCM',
                branches: [
                    [name: 'refs/heads/master']
                ],
                browser: [
                    $class: 'GitWeb',
                    repoUrl: 'https://review.lan.tribe29.com/git/?p=dependencyscanner.git'
                ],
                userRemoteConfigs: [
                    [
                        credentialsId: '058f09c4-21c9-49ae-b72b-0b9d2f465da6',
                        url: 'ssh://jenkins@review.lan.tribe29.com:29418/dependencyscanner'
                    ]
                ]
            ])
        }

        dir(SCANNER_DIR) {
            SCANNER_IMAGE = docker.build("dependencyscanner", "--tag dependencyscanner .")
        }
    }

    stage('Create BOM') {
        dir(SCANNER_DIR) {
            SCANNER_IMAGE.inside("-v ${CMK_DIR}:${CMK_DIR}") {
                sh("python3 -m dependencyscanner  --stage prod --research_file researched_2.0.0.yml --license_cache 2.0.0.cache --outfile '${BOM_PATH}' '${CMK_DIR}'")
            }
        }
    }

    stage('Upload BOM') {
        dir(SCANNER_DIR) {
            withCredentials([string(credentialsId: 'dtrack', variable: 'DTRACK_API_KEY')]) {
                withEnv(["DTRACK_URL=${DTRACK_URL}"]) {
                    SCANNER_IMAGE.inside("-v ${CMK_DIR}:${CMK_DIR} --env DTRACK_URL,DTRACK_API_KEY") {
                        sh("scripts/upload-bom --bom-path '${BOM_PATH}' --project-name 'Checkmk ${BRANCH_VERSION}' --project-version '${VERSION}'")
                    }
                }
            }
        }
    }
}

def create_source_package(WORKSPACE, CMK_VERS) {
    // The vanilla agent RPM would normally be created by "make dist", which is
    // called in the next stage, but we need to create and sign it. For this
    // reason we explicitly execute the RPM build in this separate step. The
    // "make dist" will then use the signed RPM.
    dir(WORKSPACE + "/git/agents") {
        sh("make rpm")
    }
    sign_package(WORKSPACE + "/git/agents/check-mk-agent-" + CMK_VERS + "-1.noarch.rpm", "Vanilla agent", WORKSPACE)

    stage('Create source package') {
        if (params.FAKE_WINDOWS_ARTIFACTS) {
            sh "mkdir -p ${WORKSPACE}/agents"
            if(EDITION != 'raw') {
                sh "touch ${WORKSPACE}/agents/cmk-update-agent"
                sh "touch ${WORKSPACE}/agents/cmk-update-agent-32"
            }
            sh "touch ${WORKSPACE}/agents/{check_mk_agent-64.exe,check_mk_agent.exe,check_mk_agent.msi,check_mk_agent_unsigned.msi,check_mk.user.yml,python-3.8.zip,python-3.4.zip}"
        }

        dir("git") {
            if(EDITION != 'raw') {
                sh "cp ${WORKSPACE}/agents/cmk-update-agent enterprise/agents/plugins/"
                sh "cp ${WORKSPACE}/agents/cmk-update-agent-32 enterprise/agents/plugins/"
            }
            sh "cp ${WORKSPACE}/agents/{check_mk_agent-64.exe,check_mk_agent.exe,check_mk_agent.msi,check_mk_agent_unsigned.msi,check_mk.user.yml,python-3.8.zip,python-3.4.zip} agents/windows"
            withCredentials([
                usernamePassword(
                    credentialsId: 'nexus',
                    passwordVariable: 'NEXUS_PASSWORD',
                    usernameVariable: 'NEXUS_USERNAME')
            ]) {
                sh 'make dist || cat /root/.npm/_logs/*-debug.log'
            }
        }
    }
}

def get_source_package_name(WORKSPACE, EDITION, CMK_VERS) {
    def PACKAGE_PATH = ""
    dir(WORKSPACE + "/git") {
        PACKAGE_PATH = sh(script: "ls check-mk-${EDITION}-${CMK_VERS}.c?e*.tar.gz", returnStdout: true).toString().trim()
    }
    if (PACKAGE_PATH == "") {
        throw new Exception("Found no source package path matching ${WORKSPACE}/git/check-mk-${EDITION}-${CMK_VERS}.c?e*.tar.gz")
    }
    return PACKAGE_PATH
}

def cleanup_source_package(WORKSPACE, PACKAGE_PATH) {
    stage('Cleanup source package') {
        sh "${WORKSPACE}/git/buildscripts/scripts/cleanup-source-archives.sh ${PACKAGE_PATH}"
    }
}

def copy_source_package(PACKAGE_PATH, ARCHIVE_PATH) {
    stage('Copy source package') {
        sh "mkdir -p \$(dirname ${ARCHIVE_PATH})"
        sh "cp ${PACKAGE_PATH} ${ARCHIVE_PATH}"
    }
}

def initialize_workspace(DISTRO, SOURCE_DIR, DISTRO_DIR) {
    stage(DISTRO + ' initialize workspace') {
        sh("rm -rf ${DISTRO_DIR}")
        sh("rsync -a ${SOURCE_DIR}/ ${DISTRO_DIR}/")
    }
}

def build_package(DISTRO, OMD_ENV_VARS) {
    stage(DISTRO + ' build package') {
        dir('git') {
            sh """
                case $DISTRO in
                    centos*|rh*|sles*|opensuse*)
                        ${OMD_ENV_VARS} make -C omd rpm
                        ;;
                    cma*)
                        ${OMD_ENV_VARS} make -C omd cma
                        ;;
                    *)
                        DEBFULLNAME='Checkmk Team' DEBEMAIL='feedback@checkmk.com' ${OMD_ENV_VARS} make -C omd deb
                        ;;
                esac
            """
        }
    }
}

def get_package_name(WORKSPACE, DISTRO, CMK_VERS) {
    def BASE_DIR = WORKSPACE + "/git"
    def PACKAGE_NAME = sh(script: """
        PATTERN_ROOT=check-mk-$EDITION-${CMK_VERS}
        case ${DISTRO} in
            centos*|rh*|sles*|opensuse*)
                RESULT_FILE_PATTERN=\${PATTERN_ROOT}-*.rpm
                ;;
            cma*)
                RESULT_FILE_PATTERN=\${PATTERN_ROOT}-*.cma
                ;;
            *)
                RESULT_FILE_PATTERN=\${PATTERN_ROOT}_*.deb
                ;;
        esac
        cd ${BASE_DIR}
        ls \$RESULT_FILE_PATTERN
    """, returnStdout: true).toString().trim()

    if (PACKAGE_NAME == "") {
        throw new Exception("Found no package matching ${RESULT_FILE_PATTERN} in ${BASE_DIR}")
    }

    return PACKAGE_NAME
}

def copy_package(PACKAGE_PATH, DISTRO, ARCHIVE_PATH) {
    stage(DISTRO + ' copy package') {
        sh "mkdir -p \$(dirname ${ARCHIVE_PATH})"
        sh "cp '${PACKAGE_PATH}' '${ARCHIVE_PATH}'"
    }
}

def sign_package(PACKAGE_PATH, DISTRO, WORKSPACE) {
    stage(DISTRO + ' sign package') {
        withCredentials([file(credentialsId: 'Check_MK_Release_Key', variable: 'GPG_KEY')]) {
            // --batch is needed to awoid ioctl error
            sh "gpg --batch --import ${GPG_KEY}"
        }
        withCredentials([usernamePassword(credentialsId: '9d7aca31-0043-4cd0-abeb-26a249d68261', passwordVariable: 'GPG_PASSPHRASE', usernameVariable: 'GPG_USERNAME')]) {
            sh "${WORKSPACE}/git/buildscripts/scripts/sign-packages.sh ${PACKAGE_PATH}"
        }
    }
}

def test_package(PACKAGE_PATH, NAME, WORKSPACE, GIT_DIR, CMK_VERS) {
    stage(NAME + ' test package') {
        try {
            withEnv(["PACKAGE_PATH=${PACKAGE_PATH}", "PYTEST_ADDOPTS='--junitxml=${WORKSPACE}/junit-${NAME}.xml'"]) {
                sh("make -C \"${GIT_DIR}/tests\" VERSION=${CMK_VERS} test-packaging")
            }
        } finally {
            step([$class: 'JUnitResultArchiver', testResults: 'junit-' + NAME + '.xml'])
        }
    }
}
