import java.text.SimpleDateFormat

def DISTRO_LIST_DEFAULT = ''
def NODE = ''
def DOCKER_TAG_DEFAULT
withFolderProperties{
    if(JOB_BASE_NAME == 'nightly_build_containerized') {
        DISTRO_LIST_DEFAULT = env.DISTRO_LIST
    } else {
        DISTRO_LIST_DEFAULT = env.DISTRO_LIST_TESTBUILD
    }

    NODE = env.BUILD_NODE
    DOCKER_TAG_DEFAULT = env.DOCKER_TAG_FOLDER
}

properties([
  buildDiscarder(logRotator(artifactDaysToKeepStr: '', artifactNumToKeepStr: '', daysToKeepStr: '7', numToKeepStr: '14')),
  parameters([
    string(name: 'DISTROS', defaultValue: DISTRO_LIST_DEFAULT, description: 'List of targeted distros' ),
    string(name: 'EDITION', defaultValue: 'enterprise', description: 'Edition: raw, enterprise or managed' ),
    string(name: 'DEMO', defaultValue: 'no', description: 'Demo: yes or no' ),
    string(name: 'VERSION', defaultValue: 'daily', description: 'Version: "daily" for current state of the branch, e.g. "1.6.0b2" for building the git tag "v1.6.0b2".' ),
    string(name: 'DOCKER_TAG_BUILD', defaultValue: '', description: 'DOCKER_TAG_BUILD: Custom Docker Tag to use for this build. Leave empty for default' ),
    booleanParam(name: 'FAKE_WINDOWS_ARTIFACTS', defaultValue: false, description: 'Use faked windows agent artifacts instead of building them')
  ])
])

def PACKAGE_BUILDS = [:]
def AGENT_LIST = get_agent_list(EDITION)
def AGENT_BUILDS= [:]
def DISTRO_LIST = DISTROS.split(' ');

// We don't have the "versioning" library here. For this reason we can not use versioning.select_docker_tag.
// Always use the default docker tag we got from the environment.
def BUILD_IMAGE_NAME = 'ubuntu-20.04:' + DOCKER_TAG_DEFAULT

println("Building for the following Distros:" + DISTRO_LIST)
currentBuild.description = '\nBuilding for the following Distros:\n' + DISTRO_LIST + '\nFake artifacts: ' + FAKE_WINDOWS_ARTIFACTS

def DOCKER_BUILDS = [:]
// TODO: Change to versioning.get_branch and versioning.get_cmk_version! Then
// the copy&paste below can be removed.
def BRANCH = scm.branches[0].name.replaceAll("/","-")
def CMK_VERS = get_cmk_version(BRANCH, VERSION)
def BRANCH_VERSION
def WS_ARCHIVE="WS-${JOB_NAME}-${BUILD_NUMBER}.tar.gz".replaceAll("/","-")
def GPG_KEY_DIR = '/bauwelt/etc/.gnupg'
def RELEASE_KEY_PATH = '/bauwelt/git/release/release.key'
def UPLOAD_DEST_OLD = 'bauwelt@mathias-kettner.de:/bauwelt/download/'
def UPLOAD_DEST = 'deploy@customer.checkmk.com:/var/downloads/checkmk'

def ARCHIVE_DIR = ''
def OMD_ENV_VARS = ''
if (shall_publish_package(scm, JOB_BASE_NAME)) {
    ARCHIVE_DIR = '/bauwelt/download/' + CMK_VERS
} else {
    ARCHIVE_DIR ='/tmp/jenkins-' + JOB_BASE_NAME + '/' + CMK_VERS
    // Do not use our build cache to ensure we catch build related issues. And
    // disable python optimizations to execute the build faster
    OMD_ENV_VARS = ' NEXUS_BUILD_CACHE_URL="" PYTHON_ENABLE_OPTIMIZATIONS=""'
}

def DOCKER_BASE_ARGS = "-u 0:0 --ulimit nofile=1024:1024"
def DOCKER_ARGS = "${DOCKER_BASE_ARGS} -v ${ARCHIVE_DIR}:${ARCHIVE_DIR}"

def DOCKER_REGISTRY_NO_HTTP = ''

//
// MAIN
//
node(NODE) {
    docker.withRegistry(DOCKER_REGISTRY, 'nexus') {
        docker.image(BUILD_IMAGE_NAME).inside(DOCKER_BASE_ARGS) {
            stage('Cleanup work directories') {
                clean_workpace()
            }

            stage('Checkout sources') {
                dir("${WORKSPACE}/git") {
                    checkout_git(scm, VERSION)
                    // Load libraries
                    versioning = load 'buildscripts/scripts/lib/versioning.groovy'
                    windows = load 'buildscripts/scripts/lib/windows.groovy'
                    str_mod = load 'buildscripts/scripts/lib/str_mod.groovy'
                    notify = load 'buildscripts/scripts/lib/notify.groovy'
                    withFolderProperties{
                        DOCKER_TAG = versioning.select_docker_tag(BRANCH, DOCKER_TAG_BUILD, DOCKER_TAG_DEFAULT)
                    }

                    versioning.patch_git_after_checkout(EDITION, DEMO, CMK_VERS)
                    BRANCH_VERSION = versioning.get_branch_version()

                    DOCKER_REGISTRY_NO_HTTP = str_mod.strip_protocol_from_url(DOCKER_REGISTRY)
                }
            }
        }
    }
    try {
        if (!params.FAKE_WINDOWS_ARTIFACTS) {
            AGENT_LIST.each { AGENT ->
                AGENT_BUILDS['build agent ' + AGENT] = {
                    if (AGENT == 'windows') {
                        def FOLDER_ID = currentBuild.fullProjectName.split('/')[0]
                        def WIN_PROJECT = "${FOLDER_ID}/windows-agent-build"
                        def WIN_PY_PROJECT = "${FOLDER_ID}/Windows-Python-Build"

                        sh('mkdir -p agents')

                        def WIN_BUILD = build(job: WIN_PROJECT, parameters: [string(name: 'VERSION', value: VERSION)])
                        copyArtifacts(
                            projectName: WIN_PROJECT,
                            selector: specific(WIN_BUILD.getId()),
                            target: 'agents',
                            fingerprintArtifacts: true
                        )

                        def WIN_PY_BUILD = build(job: WIN_PY_PROJECT, parameters: [string(name: 'VERSION', value: VERSION)])
                        copyArtifacts(
                            projectName: WIN_PY_PROJECT,
                            selector: specific(WIN_PY_BUILD.getId()),
                            target: 'agents',
                            fingerprintArtifacts: true
                        )

                    }
                    else if (EDITION != 'raw') {
                        docker.withRegistry(DOCKER_REGISTRY, 'nexus') {
                            docker.image(BUILD_IMAGE_NAME).inside(DOCKER_ARGS + " -u 0:0 --ulimit nofile=1024:1024 -v /var/run/docker.sock:/var/run/docker.sock --privileged") {
                                build_linux_agent_updater(AGENT, EDITION, BRANCH_VERSION, DOCKER_REGISTRY_NO_HTTP)
                            }
                        }
                    }
                }
            }
            parallel AGENT_BUILDS
        }
    }catch(Exception e) {
        notify.notify_error(e)
    }
    docker.withRegistry(DOCKER_REGISTRY, 'nexus') {
        docker.image(BUILD_IMAGE_NAME).inside(DOCKER_ARGS + " -v ${RELEASE_KEY_PATH}:${RELEASE_KEY_PATH}:ro -v ${GPG_KEY_DIR}:${GPG_KEY_DIR}:ro") {
            prepare_archive_dir(ARCHIVE_DIR, CMK_VERS)
            create_source_package(WORKSPACE, CMK_VERS)

            def SOURCE_PACKAGE_NAME = get_source_package_name(WORKSPACE, EDITION, CMK_VERS)
            def BUILD_SOURCE_PACKAGE_PATH = WORKSPACE + "/git/" + SOURCE_PACKAGE_NAME
            def FINAL_SOURCE_PACKAGE_PATH = ARCHIVE_DIR + "/" + SOURCE_PACKAGE_NAME

            copy_source_package(BUILD_SOURCE_PACKAGE_PATH, FINAL_SOURCE_PACKAGE_PATH)

            cleanup_source_package(WORKSPACE, FINAL_SOURCE_PACKAGE_PATH)
            test_package(FINAL_SOURCE_PACKAGE_PATH, "source", WORKSPACE, CMK_VERS)
            upload_package(FINAL_SOURCE_PACKAGE_PATH, SOURCE_PACKAGE_NAME, "source", scm, JOB_BASE_NAME, RELEASE_KEY_PATH, UPLOAD_DEST_OLD, UPLOAD_DEST, CMK_VERS)

            create_workspace_package(WORKSPACE, WS_ARCHIVE)
            stash_package(WORKSPACE, WS_ARCHIVE, "source", scm, JOB_BASE_NAME, RELEASE_KEY_PATH, UPLOAD_DEST, CMK_VERS)
        }
    }
}

try{
    DISTRO_LIST.each { DISTRO ->
        PACKAGE_BUILDS[DISTRO] = {
            node(NODE) {
                docker.withRegistry(DOCKER_REGISTRY, 'nexus') {
                    docker.image(DISTRO + ':' + DOCKER_TAG).inside(DOCKER_ARGS + " --privileged --hostname ${DISTRO}") {
                        clean_workpace()
                        unstash_package(WS_ARCHIVE)
                        unpack_workspace_package("git", WS_ARCHIVE)
                        withCredentials([usernamePassword(credentialsId: 'nexus', passwordVariable: 'NEXUS_PASSWORD', usernameVariable: 'NEXUS_USERNAME')]) {
                            versioning.print_image_tag()
                            build_package(DISTRO, OMD_ENV_VARS)
                        }
                    }
                    docker.image(BUILD_IMAGE_NAME).inside(DOCKER_ARGS + " -v ${RELEASE_KEY_PATH}:${RELEASE_KEY_PATH}:ro -v ${GPG_KEY_DIR}:${GPG_KEY_DIR}:ro") {
                        def PACKAGE_NAME = get_package_name(WORKSPACE, DISTRO, CMK_VERS, DEMO)
                        def BUILD_PACKAGE_PATH = WORKSPACE + "/git/" + PACKAGE_NAME
                        def FINAL_PACKAGE_PATH = ARCHIVE_DIR + "/" + PACKAGE_NAME

                        clean_venv()

                        sign_package(BUILD_PACKAGE_PATH, DISTRO, WORKSPACE)
                        test_package(BUILD_PACKAGE_PATH, DISTRO, WORKSPACE, CMK_VERS)
                        copy_package(BUILD_PACKAGE_PATH, DISTRO, ARCHIVE_DIR)
                        upload_package(FINAL_PACKAGE_PATH, PACKAGE_NAME, DISTRO, scm, JOB_BASE_NAME, RELEASE_KEY_PATH, UPLOAD_DEST_OLD, UPLOAD_DEST, CMK_VERS)
                    }
                }
            }
        }
    }
    parallel PACKAGE_BUILDS
}catch(Exception e) {
    notify.notify_error(e)
}finally {
    node(NODE) {
        stage("Remove Stashed package") {
            delete_stashed_package(DOCKER_REGISTRY_NO_HTTP, WS_ARCHIVE)
        }
        if (!shall_publish_package(scm, JOB_BASE_NAME)) {
            docker.withRegistry(DOCKER_REGISTRY, 'nexus') {
                docker.image(BUILD_IMAGE_NAME).inside(DOCKER_BASE_ARGS + " -v /tmp:/tmp") {
                    sh("rm -rf ${ARCHIVE_DIR}")
                }
            }
        }
    }
}
//
// FUNCTIONS
//

// Duplicate code with nightly-cmk-container.jenkins
def get_cmk_version(BRANCH, VERSION) {
    def DATE_FORMAT = new SimpleDateFormat("yyyy.MM.dd")
    def DATE = new Date()

    if (BRANCH == 'master' && VERSION == 'daily') {
        return DATE_FORMAT.format(DATE) // Regular daily build of master branch
    } else if (BRANCH.startsWith('sandbox') && VERSION == 'daily') {
        return DATE_FORMAT.format(DATE) + '-' + BRANCH // Experimental builds
    } else if (VERSION == 'daily') {
        return BRANCH + '-' + DATE_FORMAT.format(DATE) // version branch dailies (e.g. 1.6.0)
    } else {
        return VERSION
    }
}

def get_agent_list(EDITION) {
    if (EDITION == "raw") {
        return ["windows"]
    } else {
        return ["au-linux-64bit", "au-linux-32bit", "windows"]
    }
}

def shall_publish_package(scm, JOB_BASE_NAME) {
    return (scm.branches[0].name == 'master' || scm.branches[0].name ==~ '[0-9]+\\.[0-9]+\\.[0-9]+') && JOB_BASE_NAME == 'nightly_build_containerized'
}

def checkout_git(scm, VERSION) {
    if (VERSION == 'daily') {
        checkout(scm)
    } else {
        checkout([
            $class: 'GitSCM',
            userRemoteConfigs: scm.userRemoteConfigs,
            branches: [
                [name: 'refs/tags/v' + VERSION]
            ]
        ])
    }
}

def build_linux_agent_updater(AGENT, EDITION, BRANCH_VERSION, DOCKER_REGISTRY_NO_HTTP) {
    stage('Build agent updater ' + AGENT) {
        def SUFFIX = ""
        if (AGENT == 'au-linux-32bit') {
            SUFFIX = '-32'
        }

        withCredentials([usernamePassword(credentialsId: 'nexus', passwordVariable: 'NEXUS_PASSWORD', usernameVariable: 'NEXUS_USERNAME')]) {
            sh script: """
                cd ${WORKSPACE}/git/enterprise/agents/plugins
                BRANCH_VERSION=${BRANCH_VERSION} DOCKER_REGISTRY_NO_HTTP=${DOCKER_REGISTRY_NO_HTTP} ./make-agent-updater${SUFFIX}
            """
        }
        sh """
            mkdir -p ${WORKSPACE}/agents
            cp ${WORKSPACE}/git/enterprise/agents/plugins/cmk-update-agent${SUFFIX} ${WORKSPACE}/agents
        """
    }
}

def prepare_archive_dir(ARCHIVE_DIR, CMK_VERS) {
    sh("""
        mkdir -p ${ARCHIVE_DIR}
        echo "${CMK_VERS}" > ${ARCHIVE_DIR}/VERSION.cmk
    """)
}

def create_source_package(WORKSPACE, CMK_VERS) {
    // The vanilla agent RPM would normally be created by "make dist", which is
    // called in the next stage, but we need to create and sign it. For this
    // reason we explicitly execute the RPM build in this separate step. The
    // "make dist" will then use the signed RPM.
    dir(WORKSPACE + "/git/agents") {
        sh("make rpm")
    }
    sign_package(WORKSPACE + "/git/agents/check-mk-agent-" + CMK_VERS + "-1.noarch.rpm", "Vanilla agent", WORKSPACE)

    stage('Create source package') {
        if (!params.FAKE_WINDOWS_ARTIFACTS) {
        } else {
            sh "mkdir -p agents"
            if(EDITION != 'raw') {
                sh "touch agents/cmk-update-agent agents/cmk-update-agent-32"
            }
            sh "touch check_mk_agent-64.exe check_mk_agent.exe check_mk_agent.msi check_mk.user.yml python-3.8.zip"
        }

        dir("git") {
            if(EDITION != 'raw') {
                sh "cp ${WORKSPACE}/agents/cmk-update-agent enterprise/agents/plugins/"
                sh "cp ${WORKSPACE}/agents/cmk-update-agent-32 enterprise/agents/plugins/"
            }
            sh "cp ${WORKSPACE}/agents/{check_mk_agent-64.exe,check_mk_agent.exe,check_mk_agent.msi,check_mk.user.yml,python-3.8.zip} agents/windows"
            sh 'make dist || cat /root/.npm/_logs/*-debug.log'
        }
    }
}

def get_source_package_name(WORKSPACE, EDITION, CMK_VERS) {
    def PACKAGE_PATH = ""
    dir(WORKSPACE + "/git") {
        PACKAGE_PATH = sh(script: "ls check-mk-${EDITION}-${CMK_VERS}.c?e*.tar.gz", returnStdout: true).toString().trim()
    }
    if (PACKAGE_PATH == "") {
        throw new Exception("Found no source package path matching ${WORKSPACE}/git/check-mk-${EDITION}-${CMK_VERS}.c?e*.tar.gz")
    }
    return PACKAGE_PATH
}

def cleanup_source_package(WORKSPACE, PACKAGE_PATH) {
    stage('Cleanup source package') {
        sh "${WORKSPACE}/git/buildscripts/scripts/cleanup-source-archives.sh ${PACKAGE_PATH}"
    }
}

def copy_source_package(PACKAGE_PATH, ARCHIVE_PATH) {
    stage('Copy source package') {
        sh "cp ${PACKAGE_PATH} ${ARCHIVE_PATH}"
    }
}

def build_package(DISTRO, OMD_ENV_VARS) {
    stage(DISTRO + ' build package') {
        dir('git') {
            sh """
                case $DISTRO in
                    centos*|rh*|sles*|opensuse*)
                        ${OMD_ENV_VARS} make -C omd rpm
                        ;;
                    cma*)
                        ${OMD_ENV_VARS} make -C omd cma
                        ;;
                    *)
                        DEBFULLNAME='Checkmk Team' DEBEMAIL='feedback@checkmk.com' ${OMD_ENV_VARS} make -C omd deb
                        ;;
                esac
            """
        }
    }
}

def get_package_name(WORKSPACE, DISTRO, CMK_VERS, DEMO) {
    def BASE_DIR = WORKSPACE + "/git"
    def PACKAGE_NAME = sh(script: """
        PATTERN_ROOT=check-mk-$EDITION-${CMK_VERS}${DEMO=="yes" ? ".demo" : ""}
        case ${DISTRO} in
            centos*|rh*|sles*|opensuse*)
                RESULT_FILE_PATTERN=\${PATTERN_ROOT}-*.rpm
                ;;
            cma*)
                RESULT_FILE_PATTERN=\${PATTERN_ROOT}-*.cma
                ;;
            *)
                RESULT_FILE_PATTERN=\${PATTERN_ROOT}_*.deb
                ;;
        esac
        cd ${BASE_DIR}
        ls \$RESULT_FILE_PATTERN
    """, returnStdout: true).toString().trim()

    if (PACKAGE_NAME == "") {
        throw new Exception("Found no package matching ${RESULT_FILE_PATTERN} in ${BASE_DIR}")
    }

    return PACKAGE_NAME
}

def copy_package(PACKAGE_PATH, DISTRO, ARCHIVE_DIR) {
    stage(DISTRO + ' copy package') {
        sh "cp '${PACKAGE_PATH}' '${ARCHIVE_DIR}'"
    }
}

def sign_package(PACKAGE_PATH, DISTRO, WORKSPACE) {
    stage(DISTRO + ' sign package') {
        withCredentials([usernamePassword(credentialsId: '9d7aca31-0043-4cd0-abeb-26a249d68261', passwordVariable: 'GPG_PASSPHRASE', usernameVariable: 'GPG_USERNAME')]) {
            sh "${WORKSPACE}/git/buildscripts/scripts/sign-packages.sh ${PACKAGE_PATH}"
        }
    }
}

def test_package(PACKAGE_PATH, NAME, WORKSPACE, CMK_VERS) {
    stage(NAME + ' test package') {
        try {
            dir("${WORKSPACE}/git/tests") {
                withEnv(["PACKAGE_PATH=${PACKAGE_PATH}", "PYTEST_ADDOPTS='--junitxml=${WORKSPACE}/junit-${NAME}.xml'"]) {
                    sh "make VERSION=${CMK_VERS} test-packaging"
                }
            }
        } finally {
            step([$class: 'JUnitResultArchiver', testResults: 'junit-' + NAME + '.xml'])
        }
    }
}

def clean_workpace() {
    sh('rm -rf ${WORKSPACE}/*')
}

def clean_venv() {
    sh('rm -rf git/.venv')
}

def create_workspace_package(DIR, ARCHIVE_NAME) {
    sh("tar -cz -C ${DIR}/git/ -f ${ARCHIVE_NAME} .")
}

def unpack_workspace_package(DIR, ARCHIVE_NAME) {
    sh("mkdir -p ${DIR}")
    sh("tar -x -C ${DIR} -f ${ARCHIVE_NAME}")
}

def stash_package(FILE_PATH, FILE_NAME, NAME, scm, JOB_BASE_NAME, RELEASE_KEY_PATH, UPLOAD_DEST, CMK_VERS) {
    stage(NAME + ' upload package') {
        def FILE_BASE = sh(script: "dirname ${FILE_PATH}", returnStdout: true).toString().trim()
        def ARCHIVE_BASE = sh(script: "dirname ${FILE_BASE}", returnStdout: true).toString().trim()

        withCredentials([usernamePassword(credentialsId: 'nexus', passwordVariable: 'NEXUS_PASSWORD', usernameVariable: 'NEXUS_USERNAME')]) {
            sh """
                curl -sSf -u "${NEXUS_USERNAME}:${NEXUS_PASSWORD}" --upload-file "${FILE_PATH}/${FILE_NAME}" "${NEXUS_ARCHIVES_URL}"
            """
        }
    }
}

def upload_package(FILE_PATH, FILE_NAME, NAME, scm, JOB_BASE_NAME, RELEASE_KEY_PATH, UPLOAD_DEST_OLD, UPLOAD_DEST, CMK_VERS) {
    stage(NAME + ' upload package') {
        def FILE_BASE = sh(script: "dirname ${FILE_PATH}", returnStdout: true).toString().trim()
        def ARCHIVE_BASE = sh(script: "dirname ${FILE_BASE}", returnStdout: true).toString().trim()

        // Only 'official' builds should end up on the Website
        if (shall_publish_package(scm, JOB_BASE_NAME)) {
            sh """
                rsync -av --relative \
                    -e "ssh -o StrictHostKeyChecking=no -i ${RELEASE_KEY_PATH}" \
                    ${ARCHIVE_BASE}/./${CMK_VERS}/${FILE_NAME} \
                    ${UPLOAD_DEST_OLD}
            """
            sh """
                rsync -av \
                    --exclude '*dbgsym*.deb' \
                    -e "ssh -o StrictHostKeyChecking=no -i ${RELEASE_KEY_PATH} -p 52022" \
                    ${ARCHIVE_BASE}/./${CMK_VERS}/${FILE_NAME} \
                    ${UPLOAD_DEST}
            """
        } else {
            dir(FILE_BASE) {
                // Multiple subsequent calls overwrite the previous artifacts. For this reason
                // we always archive all available files
                archiveArtifacts("*")
            }
        }
    }
}


def unstash_package(FILE_NAME) {
    stage(FILE_NAME + ' download package') {
        withCredentials([usernamePassword(credentialsId: 'nexus', passwordVariable: 'NEXUS_PASSWORD', usernameVariable: 'NEXUS_USERNAME')]) {
            print("""
                curl -1 -sSf -o "${FILE_NAME}" "${NEXUS_ARCHIVES_URL}${FILE_NAME}"
""")
            sh """
                curl -1 -sSf -o "${FILE_NAME}" "${NEXUS_ARCHIVES_URL}${FILE_NAME}"
            """
        }
    }
}

def delete_stashed_package(DOCKER_REG, FILE_NAME) {
    def DOCKER_REPO = NEXUS_ARCHIVES_URL
    def CONTAINER = "nexus3-cli"
    def URL_ELEMENTS = NEXUS_ARCHIVES_URL.split('/')
    def NEXUS_URL = URL_ELEMENTS[0] + '//' + URL_ELEMENTS[2]
    def REPO = URL_ELEMENTS[URL_ELEMENTS.length -1]
    withCredentials([usernamePassword(credentialsId: 'nexus', passwordVariable: 'NEXUS_PASSWORD', usernameVariable: 'NEXUS_USERNAME')]) {
        sh("docker run -t -a stdout -a stderr ${DOCKER_REG}/${CONTAINER} nexus3-del-artifacts.py $NEXUS_URL $NEXUS_USERNAME $NEXUS_PASSWORD --repo $REPO --pattern ${FILE_NAME}")
    }
}
