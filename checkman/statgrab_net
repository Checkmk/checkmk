title: Network Interfaces: Traffic
agents: hpux, solaris
catalog: os/networking
license: GPL
distribution: check_mk
description:
 This check reports the network traffic, the port state and the error counters of
 interfaces using the command line tool {statgrab} on Solaris and HP-UX.

 Make sure you have the statgrab binary available on the monitored machine. Under HP-UX,
 you also need to activate the {hpux_statgrab} agent plugin.

 For details about the features and configuration of this check, please refer to the
 manpage of {if64}. This check uses the same implementation - with just a few restrictions:
 There is no information about broadcast or multicast packets. These will be shown as unicast
 packets. Furthermore, the interface type will always be 6 (Ethernet), except for {lo0},
 which will be discovered as type 24 (SoftwareLoopback).

item:
 There are three allowed ways to specify an interface: its index, which simply enumerates
 the interfaces starting from 1, its description and its alias.

inventory:
 One service is created for each interface that fulfills configurable conditions
 (rule "Network interface and switch port discovery").
 By default, these are interfaces which are currently found {up} and are of type 6, 32,
 62, 117, 127, 128, 129, 180, 181, 182, 205 or 229.

 {Grouping:} In some situations, you do not want to monitor a single
 interface but a group of interfaces that together form a pool.
 This check supports such pools by defining groups. The data of all members is
 accumulated and put together in a single grouped interface service.

cluster:
 In the case where single (ungrouped) interfaces are clustered, the corresponding
 services report only the results from the node with the highest outgoing traffic,
 since this node is likely the active node.
 In the case where interface groups are clustered, the grouping is applied across
 all nodes, potentially combining interfaces from different nodes. Note that the
 rules defining the interface groups must be configured to apply to the nodes, not
 to the cluster host (the latter has no effect). In case the grouping configurations
 vary across the nodes, the last node wins.
