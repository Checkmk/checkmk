#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Copyright (C) 2019 tribe29 GmbH - License: GNU General Public License v2
# This file is part of Checkmk (https://checkmk.com). It is subject to the terms and
# conditions defined in the file COPYING, which is part of this source code package.

# <<<df>>>
# /dev/sda3     ext4     8123200   1207512   6496392      16% /
# /dev/sda6     ext3   117794932    192192 111522544       1% /data
# /dev/sda2     ext3     8123200    220388   7483516       3% /var
# /dev/sda1     reiserfs  256666     16052    227362       7% /boot
# /dev/mapper/mirrored-database ext3  20642428   1027112  19405604       6% /mirrored/database

# Another example from a Windows 7 system:
# <<<df>>>
# SYSTEM NTFS 312569172 180648472 131920700  58% C:\
# Data NTFS 976506816 528665344 447841472  55% D:\
# PS3 PlayStation(R)3 File System 0 0 0   0% P:\

# An example with btrfs (SLES 12). Here the same device is mounted
# several times at different mount point. But must only be monitored
# once. We use the device instead of the mount point in this case.
# <<<df>>>
# /dev/sda1      btrfs       20970496 4169036  16539348      21% /
# devtmpfs       devtmpfs      497396       0    497396       0% /dev
# tmpfs          tmpfs         506312       0    506312       0% /dev/shm
# tmpfs          tmpfs         506312    6980    499332       2% /run
# tmpfs          tmpfs         506312       0    506312       0% /sys/fs/cgroup
# /dev/sda1      btrfs       20970496 4169036  16539348      21% /.snapshots
# /dev/sda1      btrfs       20970496 4169036  16539348      21% /var/tmp
# /dev/sda1      btrfs       20970496 4169036  16539348      21% /var/spool
# /dev/sda1      btrfs       20970496 4169036  16539348      21% /var/opt
# /dev/sda1      btrfs       20970496 4169036  16539348      21% /var/log

# <<<df>>>
# dev                     795652         0    795652   0% /dev
# run                     811756     11848    799908   1% /run
# /dev/sda2              1040280    716340    271512  73% /
# devtmpfs                795652         0    795652   0% /dev
# tmpfs                   811756         0    811756   0% /dev/shm
# tmpfs                   811756     11848    799908   1% /run
# tmpfs                   811756         0    811756   0% /sys/fs/cgroup
# none                    811756        12    811744   0% /var/tmp
# none                    811756         0    811756   0% /var/lock
# none                    409600     95460    314140  23% /var/log
# tmpfs                   811756     11848    799908   1% /var/run
# none                    811756        56    811700   0% /tmp
# /dev/sda1               126931     33759     86619  28% /boot
# /dev/sda5             12668904    360184  11670236   3% /persist
# <<<df>>>
# [df_inodes_start]
# dev                     198913       365    198548   0% /dev
# run                     202939       336    202603   0% /run
# /dev/sda2                65536     25533     40003  39% /
# devtmpfs                198913       365    198548   0% /dev
# tmpfs                   202939         1    202938   0% /dev/shm
# tmpfs                   202939       336    202603   0% /run
# tmpfs                   202939         7    202932   0% /sys/fs/cgroup
# none                    202939         4    202935   0% /var/tmp
# none                    202939         1    202938   0% /var/lock
# none                    202939        28    202911   0% /var/log
# tmpfs                   202939       336    202603   0% /var/run
# none                    202939        27    202912   0% /tmp
# /dev/sda1                32768        25     32743   0% /boot
# /dev/sda5               799680       118    799562   0% /persist
# [df_inodes_end]

# <<<df>>>
# C:\ NTFS 41838588 21776048 20062540 53% C:\
# C:\Program Files\Vision Solutions\Double-Take\Service\MountDir\usauhtest0010_c061b170-ad3f-473f-92ce-088c97fce98e_C\ NTFS 41835516 11895180 29940336 29% C:\Program Files\Vision Solutions\Double-Take\Service\MountDir\usauhtest0010_c061b170-ad3f-473f-92ce-088c97fce98e_C\

inventory_df_rules = []
inventory_df_exclude_fs = ['tmpfs', 'nfs', 'smbfs', 'cifs', 'iso9660']


def parse_df(info):
    def parse_blocks_subsection(blocks_subsection):
        volume_info = {}
        df_blocks = []
        btrfs_devices = set()
        for line in blocks_subsection:
            try:
                int(line[1])
            except ValueError:
                pass
            else:
                line = [line[0], None] + line[1:]

            # Handle known cases, where the file system contains spaces
            for index, entry in enumerate(line):
                if entry == "NTFS":
                    line = [" ".join(line[:index])] + [line[index]] + line[index + 1:index + 5] + [
                        " ".join(line[index + 5:])
                    ]
                    break

            if line[2] == "File" and line[3] == "System":
                line = [line[0], " ".join(line[1:4])] + line[4:]

            fs_type = line[1]
            # This particular bit of magic originated in Werk #2671 and has the purpose of avoiding duplicate checks,
            # as btrfs filesystems are often mounted at multiple mountpoints. We keep it for compatibility.
            if fs_type == "btrfs":
                device = line[0]
                if device not in btrfs_devices:
                    btrfs_devices.add(device)
                    mountpoint = "btrfs " + device
                else:
                    continue

            else:
                mountpoint = " ".join(line[6:]).replace('\\', '/')  # Windows \ is replaced with /

            if mountpoint in ("/etc/resolv.conf", "/etc/hostname", "/etc/hosts"):
                continue

            # exclude filesystems without size
            try:
                if int(line[2]) == 0:
                    continue
            except ValueError:
                continue

            # Beware: the 6th column of df ("used perc") may includes 5% which are reserved
            # for the superuser, whereas the 4th colum ("used MB") does *not* include that.
            # Beware(2): the column used_mb does not account for the reserved space for
            # superusers. So we rather use the column 'avail' and subtract that from total
            # to compute the used space.
            size_mb = int(line[2]) / 1024.0
            avail_mb = int(line[4]) / 1024.0
            used_mb = int(line[3]) / 1024.0
            reserved_mb = size_mb - avail_mb - used_mb  # reserved for root
            df_blocks.append((mountpoint, size_mb, avail_mb, reserved_mb))

            volume_name = line[0]
            volume_info[mountpoint] = {
                "volume_name": volume_name,
                "fs_type": fs_type,
            }

        return df_blocks, volume_info

    def parse_inodes_subsection(inodes_subsection):
        df_inodes = []
        for line in inodes_subsection:
            try:
                int(line[1])
            except ValueError:
                pass
            else:
                line = [line[0], None] + line[1:]

            try:
                inodes_total = int(line[2])
                inodes_avail = int(line[4])
            except ValueError:
                continue

            mountpoint = line[-1]
            df_inodes.append((mountpoint, inodes_total, inodes_avail))
        return df_inodes

    blocks_subsection = []
    inodes_subsection = []

    is_inode = False
    for line in info:
        if line[-1] == '[df_inodes_start]':
            is_inode = True
            continue
        elif line[-1] == '[df_inodes_end]':
            is_inode = False
            continue

        if is_inode:
            inodes_subsection.append(line)
        else:
            blocks_subsection.append(line)

    return parse_blocks_subsection(blocks_subsection), parse_inodes_subsection(inodes_subsection)


def _filter_by_exclude_rule(inv_rule_excludes, iterable):
    """exclude these mount points (/tmp, /proc, whatever user wants)"""
    for df_block in iterable:
        if df_block[0] not in inv_rule_excludes:
            yield df_block


def _filter_by_type(volume_info, ignore_fs_types, never_ignore_mountpoints, iterable):

    for df_block in iterable:
        if volume_info[df_block[0]]["fs_type"] not in ignore_fs_types:
            yield df_block
            continue

        # Filesystem is not ignored, so check against mount point patterns
        for p in never_ignore_mountpoints:
            if p[0] == "~" and regex(p[1:]).match(df_block[0]):
                yield df_block
                continue

            if df_block[0] == p:
                yield df_block


def _format_with_description(description, mountpoint):
    """
    TODO: maybe do this only if description != mountpoint
    """
    return "%s %s" % (description, mountpoint)


def _get_item_list_from_blocks(df_blocks):
    """return the mountpoint"""  # TODO: fix this. Should include optional description
    return [df_block[0] for df_block in df_blocks]


def _is_grouped_item(params):
    return "patterns" in params


def inventory_df(parsed):
    inventory_options = host_extra_conf_merged(host_name(), inventory_df_rules)
    include_volume_name_settings = inventory_options.get("include_volume_name", False)

    if include_volume_name_settings is False:
        include_volume_name = False
        grouping_behaviour = "mountpoint"
    else:
        include_volume_name = True
        if include_volume_name_settings is True:
            # Legacy configuration without explicit grouping behaviour
            grouping_behaviour = "mountpoint"
        else:
            #  ( {'include_volume_name': (True, 'volume_name_and_mountpoint')}, [], ALL_HOSTS, {} ),
            grouping_behaviour = include_volume_name_settings[1]

    ignore_fs_types = inventory_options.get("ignore_fs_types", inventory_df_exclude_fs)
    never_ignore_mountpoints = inventory_options.get("never_ignore_mountpoints", [])

    (df_blocks, volume_info), df_inodes = parsed

    filtered_blocks = _filter_by_exclude_rule(inventory_df_exclude_mountpoints, df_blocks)
    filtered_blocks = _filter_by_type(volume_info, ignore_fs_types, never_ignore_mountpoints,
                                      filtered_blocks)

    #Always exclude filesystems below dockers local storage area
    #and also exclude docker mounts in containers which are reported
    #by the agent when the agent is executed in the container context
    filtered_blocks = (mp for mp in filtered_blocks if not mp[0].startswith("/var/lib/docker/"))

    mplist = _get_item_list_from_blocks(filtered_blocks)

    # Modify the df_blocks and df_inodes to include the volume name
    # and hand the data over to the inventory function, this enables grouping based on volume and mountpoint
    if include_volume_name and grouping_behaviour == "volume_name_and_mountpoint":
        df_blocks, df_inodes = _add_volume_name(df_blocks, df_inodes, volume_info, mplist)
        mplist = [x[0] for x in df_blocks]

    for mountpoint, params in df_inventory(mplist):
        if "patterns" in params:
            # Add the grouping_behaviour info to the discovered parameters of this service. With this information
            # the check can easily reconstruct the discovered grouping.
            params["grouping_behaviour"] = grouping_behaviour
        elif include_volume_name and grouping_behaviour == "mountpoint":
            # Somehow the user wanted to see the volume name in the service description,
            # but the grouping itself is based on the mountpoint only
            # => The df_inventory returns a list of mountpoints and mountpoint groups
            # Add the volume name as prefix for single mountpoints
            mountpoint = "%s %s" % (volume_info[mountpoint]["volume_name"], mountpoint)

        params["include_volume_name"] = include_volume_name
        yield mountpoint, params


# Legacy params
def _get_mountpoint_from_item(item, params, volume_info):
    volume_and_mp_to_mp = {
        ("%s %s" % (volume_info[mp]["volume_name"], mp)): mp for mp in volume_info
    }
    if "patterns" in params or item in volume_info:
        mountpoint = item
    elif item in volume_and_mp_to_mp:
        mountpoint = volume_and_mp_to_mp[item]
    else:
        mountpoint = item
    return mountpoint


def _add_volume_name(df_blocks, df_inodes, volume_info, only_mp=None):
    # Modify the df_blocks and df_inodes mount points to include the volume name
    df_blocks_volume = []
    df_inodes_volume = []
    for entry in df_blocks:
        if only_mp and entry[0] not in only_mp:
            continue
        # The parse function explictly creates a correspondin volume_info entry for each df_block
        mountpoint_with_volume = "%s %s" % (volume_info[entry[0]]["volume_name"], entry[0])
        df_blocks_volume.append((mountpoint_with_volume,) + entry[1:])
    for entry in df_inodes:
        if only_mp and entry[0] not in only_mp:
            continue
        # There is no guarantee that the inode mountpoint is in volume_info, check parse func
        if entry[0] not in volume_info:
            continue
        mountpoint_with_volume = "%s %s" % (volume_info[entry[0]]["volume_name"], entry[0])
        df_inodes_volume.append((mountpoint_with_volume,) + entry[1:])

    return df_blocks_volume, df_inodes_volume


def check_df(item, params, parsed):
    (df_blocks, volume_info), df_inodes = parsed

    if "include_volume_name" not in params:
        item = _get_mountpoint_from_item(item, params, volume_info)

    # Check if the item is not the actual mountpoint and modify the data accordingly
    elif params.get("include_volume_name"):
        if "patterns" not in params:
            # Single mountpoints with prefixed volume name
            item = _get_mountpoint_from_item(item, params, volume_info)
        elif params["grouping_behaviour"] == "volume_name_and_mountpoint":
            # Filesystem group
            # There is no need to modify the item name, since is a custom text  and not used in for pattern matching.
            # The "volume_name_and_mount" grouping option however, requires the modification of the df_blocks
            # and df_inodes variables. After the modification these variables also include the volume name
            # which will be used during for group matching
            df_blocks, df_inodes = _add_volume_name(df_blocks, df_inodes, volume_info)

    return df_check_filesystem_list(item, params, df_blocks, df_inodes)


check_info['df'] = {
    "parse_function": parse_df,
    "inventory_function": inventory_df,
    "check_function": check_df,
    "service_description": "Filesystem %s",
    "has_perfdata": True,
    "group": "filesystem",
    "default_levels_variable": "filesystem_default_levels",
    "includes": ["size_trend.include", "df.include"],
}
