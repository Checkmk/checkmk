#!/usr/bin/python
# -*- encoding: utf-8; py-indent-offset: 4 -*-
# +------------------------------------------------------------------+
# |             ____ _               _        __  __ _  __           |
# |            / ___| |__   ___  ___| | __   |  \/  | |/ /           |
# |           | |   | '_ \ / _ \/ __| |/ /   | |\/| | ' /            |
# |           | |___| | | |  __/ (__|   <    | |  | | . \            |
# |            \____|_| |_|\___|\___|_|\_\___|_|  |_|_|\_\           |
# |                                                                  |
# | Copyright Mathias Kettner 2014             mk@mathias-kettner.de |
# +------------------------------------------------------------------+
#
# This file is part of Check_MK.
# The official homepage is at http://mathias-kettner.de/check_mk.
#
# check_mk is free software;  you can redistribute it and/or modify it
# under the  terms of the  GNU General Public License  as published by
# the Free Software Foundation in version 2.  check_mk is  distributed
# in the hope that it will be useful, but WITHOUT ANY WARRANTY;  with-
# out even the implied warranty of  MERCHANTABILITY  or  FITNESS FOR A
# PARTICULAR PURPOSE. See the  GNU General Public License for more de-
# tails. You should have  received  a copy of the  GNU  General Public
# License along with GNU Make; see the file  COPYING.  If  not,  write
# to the Free Software Foundation, Inc., 51 Franklin St,  Fifth Floor,
# Boston, MA 02110-1301 USA.

from cmk.gui.plugins.metrics.check_mk import metric_number_with_precision
# If the size_trend function is not provided via size_trend.include raise
# an exception to provide an error message to the user. If dependencies
# between include files are possible this will not be necessary anymore.
if 'size_trend' not in globals():

    def size_trend(*_args, **_kwargs):  # pylint: disable=function-redefined
        raise MKGeneralException('Function size_trend not found. Please include '
                                 '"size_trend.include" in your check')


# Common include file for all filesystem checks (df, df_netapp, hr_fs, ...)

# Settings for filesystem checks (df, df_vms, df_netapp and maybe others)
filesystem_levels = []  # obsolete. Just here to check config and warn if changed
filesystem_default_levels = {}  # can also be dropped some day in future

# Filesystems to ignore (shouldn't be sent by agent anyway)
inventory_df_exclude_mountpoints = ['/dev']

# Grouping of filesystems into groups that are monitored as one entity
# Example:
# filesystem_groups = [
#     ( [ ( "Storage pool", "/data/pool*" ) ], [ 'linux', 'prod' ], ALL_HOSTS ),
#     ( [ ( "Backup space 1", "/usr/backup/*.xyz" ),
#         ( "Backup space 2", "/usr/backup2/*.xyz" ) ], ALL_HOSTS ),
# ]
filesystem_groups = []

# Alternative syntax for parameters:
# {  "levels"         : (80, 90),  # levels in percent
#    "magic"          : 0.5,       # magic factor
#    "magic_normsize" : 20,        # normsize in GB
#    "levels_low"     : (50, 60),  # magic never lowers levels below this (percent)
#    "trend_range"    : 24,        # hours
#    "trend_mb"       : (10, 20),  # MB of change during trend_range
#    "trend_perc"     : (1, 2),    # Percent change during trend_range
#    "trend_timeleft" : (72, 48)   # run time left in hours until full
# }

factory_settings["filesystem_default_levels"] = {
    "levels": (80.0, 90.0),  # warn/crit in percent
    "magic_normsize": 20,  # Standard size if 20 GB
    "levels_low": (50.0, 60.0),  # Never move warn level below 50% due to magic factor
    "trend_range": 24,
    "trend_perfdata": True,  # do send performance data for trends
    "show_levels": "onmagic",
    "inodes_levels": (10.0, 5.0),
    "show_inodes": "onlow",
    "show_reserved": False,
}


def mountpoints_in_group(mplist, patterns):
    matching_mountpoints = set()
    for mountpoint in mplist:
        for pattern in patterns:
            if fnmatch.fnmatch(mountpoint, pattern):
                matching_mountpoints.add(mountpoint)
                break
    return matching_mountpoints


def ungrouped_mountpoints_and_groups(mplist, group_patterns):
    ungrouped_mountpoints = set(mplist)
    groups = {}
    for group_name, patterns in group_patterns.items():
        groups[group_name] = mountpoints_in_group(mplist, patterns)
        ungrouped_mountpoints = ungrouped_mountpoints.difference(groups[group_name])
    return ungrouped_mountpoints, groups


def df_inventory(mplist):
    group_patterns = {}
    for line in host_extra_conf(host_name(), filesystem_groups):
        for group_name, pattern in line:
            group_patterns.setdefault(group_name, []).append(pattern)

    ungrouped_mountpoints, groups = ungrouped_mountpoints_and_groups(mplist, group_patterns)

    return [(mp, {}) for mp in ungrouped_mountpoints] \
            + [(group, {"patterns" : group_patterns[group]}) for group in groups]


# Users might have set filesystem_default_levels to old format like (80, 90)


# needed by df, df_netapp and vms_df and maybe others in future:
# compute warning and critical levels. Takes into account the size of
# the filesystem and the magic number. Since the size is only known at
# check time this function's result cannot be precompiled.
def get_filesystem_levels(mountpoint, size_gb, params):
    mega = 1024 * 1024
    giga = mega * 1024
    # Start with factory settings
    levels = factory_settings["filesystem_default_levels"].copy()

    def convert_legacy_levels(value):
        if isinstance(params, tuple) or not params.get("flex_levels"):
            return tuple(map(float, value))
        return value

    # convert default levels to dictionary. This is in order support
    # old style levels like (80, 90)
    if isinstance(filesystem_default_levels, dict):
        fs_default_levels = filesystem_default_levels.copy()
        fs_levels = fs_default_levels.get("levels")
        if fs_levels:
            fs_default_levels["levels"] = convert_legacy_levels(fs_levels)
        levels.update(filesystem_default_levels)
    else:
        levels = factory_settings["filesystem_default_levels"].copy()
        levels["levels"] = convert_legacy_levels(filesystem_default_levels[:2])
        if len(filesystem_default_levels) == 2:
            levels["magic"] = None
        else:
            levels["magic"] = filesystem_default_levels[2]

    # If params is a dictionary, make that override the default values
    if isinstance(params, dict):
        levels.update(params)

    else:  # simple format - explicitely override levels and magic
        levels["levels"] = convert_legacy_levels(params[:2])
        if len(params) >= 3:
            levels["magic"] = params[2]

    # Determine real warn, crit levels
    if isinstance(levels["levels"], tuple):
        warn, crit = levels["levels"]
    else:
        # A list of levels. Choose the correct one depending on the
        # size of the current filesystem. We do not make the first
        # rule match, but that with the largest size_gb. That way
        # the order of the entries is not important.
        found = False
        found_size = 0
        for to_size, this_levels in levels["levels"]:
            if size_gb * giga > to_size and to_size >= found_size:
                warn, crit = this_levels
                found_size = to_size
                found = True
        if not found:
            warn, crit = 100.0, 100.0  # entry not found in list

    # Take into account magic scaling factor (third optional argument
    # in check params). A factor of 1.0 changes nothing. Factor should
    # be > 0 and <= 1. A smaller factor raises levels for big file systems
    # bigger than 100 GB and lowers it for file systems smaller than 100 GB.
    # Please run df_magic_factor.py to understand how it works.

    magic = levels.get("magic")
    # We need a way to disable the magic factor so check
    # if magic not 1.0
    if magic and magic != 1.0:
        # convert warn/crit to percentage
        if not isinstance(warn, float):
            warn = savefloat(warn * mega / float(size_gb * giga)) * 100
        if not isinstance(crit, float):
            crit = savefloat(crit * mega / float(size_gb * giga)) * 100

        normsize = levels["magic_normsize"]
        hgb_size = size_gb / float(normsize)
        felt_size = hgb_size**magic
        scale = felt_size / hgb_size
        warn_scaled = 100 - ((100 - warn) * scale)
        crit_scaled = 100 - ((100 - crit) * scale)

        # Make sure, levels do never get too low due to magic factor
        lowest_warning_level, lowest_critical_level = levels["levels_low"]
        if warn_scaled < lowest_warning_level:
            warn_scaled = lowest_warning_level
        if crit_scaled < lowest_critical_level:
            crit_scaled = lowest_critical_level
    else:
        if not isinstance(warn, float):
            warn_scaled = savefloat(warn * mega / float(size_gb * giga)) * 100
        else:
            warn_scaled = warn

        if not isinstance(crit, float):
            crit_scaled = savefloat(crit * mega / float(size_gb * giga)) * 100
        else:
            crit_scaled = crit

    size_mb = size_gb * 1024
    warn_mb = savefloat(size_mb * warn_scaled / 100)
    crit_mb = savefloat(size_mb * crit_scaled / 100)
    levels["levels_mb"] = (warn_mb, crit_mb)
    if isinstance(warn, float):
        if warn_scaled < 0 and crit_scaled < 0:
            label = 'warn/crit at free space below'
            warn_scaled *= -1
            crit_scaled *= -1
        else:
            label = 'warn/crit at'
        levels["levels_text"] = "(%s %s/%s)" % (label, get_percent_human_readable(warn_scaled),
                                                get_percent_human_readable(crit_scaled))
    else:
        if warn * mega < 0 and crit * mega < 0:
            label = 'warn/crit at free space below'
            warn *= -1
            crit *= -1
        else:
            label = 'warn/crit at'
        warn_hr = get_bytes_human_readable(warn * mega)
        crit_hr = get_bytes_human_readable(crit * mega)
        levels["levels_text"] = "(%s %s/%s)" % (label, warn_hr, crit_hr)

    if "inodes_levels" in params:
        if isinstance(levels["inodes_levels"], tuple):
            warn, crit = levels["inodes_levels"]
        else:
            # A list of inode levels. Choose the correct one depending on the
            # size of the current filesystem. We do not make the first
            # rule match, but that with the largest size_gb. That way
            # the order of the entries is not important.
            found = False
            found_size = 0
            for to_size, this_levels in levels["inodes_levels"]:
                if size_gb * giga > to_size and to_size >= found_size:
                    warn, crit = this_levels
                    found_size = to_size
                    found = True
            if not found:
                warn, crit = 100.0, 100.0  # entry not found in list
        levels["inodes_levels"] = warn, crit
    else:
        levels["inodes_levels"] = (None, None)

    return levels


# New function for checks that support groups.
def df_check_filesystem_list(item, params, fslist_blocks, fslist_inodes=None):

    blocks_info = {
        mp: {
            "size_mb": size_mb,
            "avail_mb": avail_mb,
            "reserved_mb": reserved_mb,
        } for (mp, size_mb, avail_mb, reserved_mb) in fslist_blocks
    }

    inodes_info = {}
    if fslist_inodes:
        inodes_info = {
            mp: {
                "inodes_total": inodes_total,
                "inodes_avail": inodes_avail,
            } for (mp, inodes_total, inodes_avail) in fslist_inodes
        }

    if "patterns" not in params:
        data = blocks_info.get(item)
        if not data:
            return
        inodes_data = inodes_info.get(item, {})
        return df_check_filesystem_single(item, data["size_mb"],
                                          data["avail_mb"], data["reserved_mb"],
                                          inodes_data.get("inodes_total", None),
                                          inodes_data.get("inodes_avail", None), params)

    def add_mp_group(metric, info, mountpoints_group):
        return sum(
            block_info[metric] for (mp, block_info) in info.items() if mp in mountpoints_group)

    patterns = params["patterns"]
    matching_mountpoints = mountpoints_in_group(blocks_info.keys(), patterns)
    count = len(matching_mountpoints)
    if count == 0:
        return 3, "No filesystem matching the patterns"

    total_size_mb = add_mp_group("size_mb", blocks_info, matching_mountpoints)
    total_avail_mb = add_mp_group("avail_mb", blocks_info, matching_mountpoints)
    total_reserved_mb = add_mp_group("reserved_mb", blocks_info, matching_mountpoints)

    total_inodes = add_mp_group("inodes_total", inodes_info, matching_mountpoints)
    total_inodes_avail = add_mp_group("inodes_avail", inodes_info, matching_mountpoints)

    status, infotext, perfdata = df_check_filesystem_single(item, total_size_mb, total_avail_mb,
                                                            total_reserved_mb, total_inodes,
                                                            total_inodes_avail, params)
    infotext += " (%d filesystems)" % count
    return status, infotext, perfdata


def df_check_filesystem_single(mountpoint,
                               size_mb,
                               avail_mb,
                               reserved_mb,
                               inodes_total,
                               inodes_avail,
                               params,
                               this_time=None):
    if size_mb == 0:
        return (1, "Size of filesystem is 0 MB", [])

    try:
        show_levels = params.get("show_levels")
        subtract_reserved = bool(params.get("subtract_reserved")) and reserved_mb > 0
        show_reserved = params.get("show_reserved") and reserved_mb > 0
    except AttributeError:
        show_levels = False
        subtract_reserved = False
        show_reserved = False

    used_mb = size_mb - avail_mb
    used_max = size_mb
    if subtract_reserved:
        used_mb -= reserved_mb
        used_max -= reserved_mb

    used_perc = 100.0 * (float(used_mb) / used_max)

    # Get warning and critical levels already with 'magic factor' applied
    levels = get_filesystem_levels(mountpoint, size_mb / 1024., params)
    warn_mb, crit_mb = levels["levels_mb"]

    used_hr = get_bytes_human_readable(used_mb * 1024 * 1024)
    used_max_hr = get_bytes_human_readable(used_max * 1024 * 1024)
    used_perc_hr = get_percent_human_readable(used_perc)
    # If both numbers end with the same unit, then drop the first one
    if used_hr[-2:] == used_max_hr[-2:]:
        used_hr = used_hr[:-3]

    infotext = "%s used (%s of %s)" % (used_perc_hr, used_hr, used_max_hr)

    if warn_mb < 0.0:
        # Negative levels, so user configured thresholds based on space left. Calculate the
        # upper thresholds based on the size of the filesystem
        crit_mb = used_max + crit_mb
        warn_mb = used_max + warn_mb

    status = 0
    if used_mb >= crit_mb:
        status = 2
    elif used_mb >= warn_mb:
        status = 1

    # TODO: In some future version use a fixed name as perf variable
    perf_var = mountpoint.replace(" ", "_")
    perfdata = [(perf_var, used_mb, warn_mb, crit_mb, 0, size_mb), ('fs_size', size_mb)]

    if show_levels == "always" or \
        (show_levels == "onproblem" and status > 0) or \
        (show_levels == "onmagic" and (status > 0 or levels.get("magic", 1.0) != 1.0)):
        infotext += ", " + levels["levels_text"]

    if show_reserved:
        reserved_perc = 100.0 * float(reserved_mb) / size_mb
        reserved_perc_hr = get_percent_human_readable(reserved_perc)
        reserved_hr = get_bytes_human_readable(reserved_mb * 1024 * 1024)
        if subtract_reserved:
            infotext += ", additionally reserved for root: %s" % reserved_hr
        else:
            infotext += ", therein reserved for root: %s (%s)" \
                        % (reserved_perc_hr, reserved_hr)

    if subtract_reserved:
        perfdata.append(("fs_free", avail_mb, None, None, 0, size_mb))

    if subtract_reserved or show_reserved:
        perfdata.append(("reserved", reserved_mb))

    if levels.get("trend_range"):
        trend_status, trend_infotext, trend_perfdata = size_trend('df', mountpoint, "disk", levels,
                                                                  used_mb, size_mb, this_time)
        status = max(status, trend_status)
        infotext += trend_infotext
        perfdata.extend(trend_perfdata)

    ista, ii, ip = check_inodes(levels, inodes_total, inodes_avail)

    return max(status, ista), infotext + ii, perfdata + ip


def check_inodes(levels, inodes_total, inodes_avail):

    if not inodes_total:
        return 0, "", []

    inodes_warn, inodes_crit = levels["inodes_levels"]
    human_readable_func = metric_number_with_precision

    # Levels in absolute numbers
    if isinstance(inodes_warn, int):
        inodes_warn = inodes_total - inodes_warn
        inodes_crit = inodes_total - inodes_crit

    # Levels in percent
    elif isinstance(inodes_warn, float):
        inodes_warn = (100 - inodes_warn) / 100.0 * inodes_total
        inodes_crit = (100 - inodes_crit) / 100.0 * inodes_total
        human_readable_func = lambda x: get_percent_human_readable(100.0 * x / inodes_total)

    inode_status, infotext, i_perf = check_levels(inodes_total - inodes_avail,
                                                  'inodes_used', (inodes_warn, inodes_crit),
                                                  human_readable_func=human_readable_func,
                                                  infoname="Inodes Used")

    i_perf[0] += (0, inodes_total)  # because check_levels does not include min, max

    # Only show inodes if they are at less then 50%
    show_inodes = levels["show_inodes"]
    inodes_avail_perc = 100.0 * inodes_avail / inodes_total
    if show_inodes == "always" or \
        (show_inodes == "onlow" and (inode_status or inodes_avail_perc < 50)) or \
        (show_inodes == "onproblem" and inode_status):
        infotext = ", %s, inodes available: %s/%s" % (infotext,
                                                      metric_number_with_precision(inodes_avail),
                                                      get_percent_human_readable(inodes_avail_perc))
    else:
        infotext = ""

    return inode_status, infotext, i_perf
