#!/usr/bin/env python3
# Copyright (C) 2025 Checkmk GmbH - License: GNU General Public License v2
# This file is part of Checkmk (https://checkmk.com). It is subject to the terms and
# conditions defined in the file COPYING, which is part of this source code package.

"""
Code Coverage Database Storage Script.

This module provides functionality to insert code coverage statistics from CSV files
into PostgreSQL database tables used by Checkmk's code coverage tracking system.

The script supports:
- Reading coverage data from CSV files generated by code_coverage_summary.py
- Inserting summary statistics into cmk_code_coverage_summary table
- Optionally inserting per-module coverage data

Usage with minimum required arguments:
    python store_code_coverage.py --csv-file ./results/coverage/coverage.csv \
        --makefile-target test-unit-all-coverage --alias "test-unit-all-coverage-master" \
        --git-commit-hash abc12345678 --commit-time 2025-10-16T12:05:43

Optional arguments can be passed via environment variables:
    --dbhost: POSTGRES_HOST
    --dbport: POSTGRES_PORT
    --dbname: POSTGRES_DB,
    --dbuser: QA_POSTGRES_USER
    --jenkins-build-id: BUILD_NUMBER
    --sslmode: QA_POSTGRES_SSLMODE
    --sslrootcert: QA_POSTGRES_SSLROOTCERT
    --sslcert: QA_POSTGRES_SSLCERT
    --sslkey: QA_POSTGRES_SSLKEY

Postres user password is read from environment variable QA_POSTGRES_PASSWORD.
If QA_POSTGRES_PASSWORD is not set, SSL certificates must be provided.

Database Schema:
    Relies on tables defined in code_coverage_tables.sql including:
    - cmk_test_run_types: Test run type definitions
    - cmk_test_runs: Individual test run records
    - cmk_code_coverage_summary: Aggregated coverage statistics
    - cmk_module_code_coverage: Per-module detailed coverage data
"""

import argparse
import csv
import logging
import os
import subprocess
from collections.abc import Callable, Iterator
from contextlib import contextmanager
from datetime import datetime
from pathlib import Path
from typing import Any, get_args, Literal

import psycopg
from psycopg import sql
from psycopg.errors import Error as PsycopgError
from typing_extensions import TypedDict

logging.basicConfig()
logger = logging.getLogger(__name__)

SslMode = Literal["disable", "allow", "prefer", "require", "verify-ca", "verify-full"]

ModuleCoverageData = list[dict[str, str | int | float]]


def get_current_git_branch() -> str:
    result = subprocess.run(
        ["git", "rev-parse", "--abbrev-ref", "HEAD"],
        capture_output=True,
        text=True,
        check=True,
    )
    return result.stdout.strip()


git_branch = get_current_git_branch()
logger.info(f"Current git branch: {git_branch}")


class CoverageStats(TypedDict):
    """Coverage statistics from CSV."""

    lines_coverage_percent: float
    functions_coverage_percent: float
    covered_lines: int
    total_lines: int
    covered_functions: int
    total_functions: int


class CodeCoverageDb:
    """
    Database interface for storing code coverage data.

    Manages connections and operations for the cmk_code_coverage_summary table
    and related test run metadata in PostgreSQL.
    """

    def __init__(
        self,
        host: str,
        port: int,
        dbname: str,
        user: str,
        sslrootcert: Path | None = None,
        sslcert: Path | None = None,
        sslkey: Path | None = None,
        sslmode: SslMode = "allow",
    ) -> None:
        """Initialize database connection for code coverage data."""
        self.host = host
        self.port = port
        self.dbname = dbname
        self.user = user
        self.password = os.getenv("QA_POSTGRES_PASSWORD")
        self.sslmode = sslmode
        self.sslrootcert = sslrootcert
        self.sslcert = sslcert
        self.sslkey = sslkey

        if self.password:
            self.dsn = f"dbname={self.dbname} user={self.user} host={self.host} port={self.port} password={self.password}"
        elif self.sslcert and self.sslkey and self.sslrootcert:
            self.dsn = (
                f"sslmode={self.sslmode} dbname={self.dbname} user={self.user} "
                f"host={self.host} port={self.port} sslrootcert={self.sslrootcert} "
                f"sslcert={self.sslcert} sslkey={self.sslkey}"
            )
        else:
            raise ValueError("Database password or SSL certificates must be provided")

        self.connection = psycopg.connect(self.dsn, autocommit=True)
        logger.info("Connected to database %s@%s:%s", self.dbname, self.host, self.port)

    def __enter__(self) -> "CodeCoverageDb":
        return self

    def __exit__(
        self, exc_type: type[BaseException] | None, exc_val: BaseException | None, exc_tb: Any
    ) -> None:
        if not self.connection.closed:
            self.connection.close()
            logger.debug("Database connection closed")

    def close(self) -> None:
        if not self.connection.closed:
            self.connection.close()

    @contextmanager
    def _cursor(self) -> Iterator[psycopg.cursor.Cursor]:  # type: ignore[misc]
        """Return an active cursor in a new autocommit connection."""
        with self.connection.cursor() as cursor:
            yield cursor

    def _get_or_create_record(
        self,
        table: str,
        select_conditions: dict[str, Any],
        insert_values: dict[str, Any],
        returning_column: str = "id",
    ) -> int:
        """
        Generic method to get existing record or create new one.

        Args:
            table: Table name to query/insert
            select_conditions: Conditions for SELECT query
            insert_values: Values for INSERT query
            returning_column: Column to return from INSERT

        Returns:
            ID of existing or newly created record
        """
        with self._cursor() as cursor:
            where_conditions = [
                sql.SQL("{} = %s").format(sql.Identifier(k)) for k in select_conditions.keys()
            ]
            where_clause = sql.SQL(" AND ").join(where_conditions)

            select_query = sql.SQL(
                "SELECT {returning_column} FROM {table} WHERE {where_clause}"
            ).format(
                returning_column=sql.Identifier(returning_column),
                table=sql.Identifier(table),
                where_clause=where_clause,
            )
            logger.debug("Executing select query:\n%s", select_query.as_string(cursor))
            try:
                cursor.execute(select_query, list(select_conditions.values()))
            except PsycopgError as e:
                logger.error("Error executing select query: %s", e)
                raise
            if result := cursor.fetchone():
                return int(result[0])

            columns = sql.SQL(", ").join(sql.Identifier(k) for k in insert_values.keys())
            placeholders = sql.SQL(", ").join([sql.Placeholder()] * len(insert_values))

            insert_query = sql.SQL(
                "INSERT INTO {table} ({columns}) VALUES ({placeholders}) RETURNING {returning_column}"
            ).format(
                table=sql.Identifier(table),
                columns=columns,
                placeholders=placeholders,
                returning_column=sql.Identifier(returning_column),
            )
            logger.debug("Executing insert query:\n%s", insert_query.as_string(cursor))
            try:
                cursor.execute(insert_query, list(insert_values.values()))
            except PsycopgError as e:
                logger.error("Error executing insert query: %s", e)
                raise
            result = cursor.fetchone()
            if not result:
                msg = f"Failed to create record in {table}"
                raise ValueError(msg)
            return int(result[0])

    def _get_or_create_test_run_type(self, makefile_target: str, alias: str) -> int:
        return self._get_or_create_record(
            table="cmk_test_run_types",
            select_conditions={"makefile_target": makefile_target, "alias": alias},
            insert_values={"makefile_target": makefile_target, "alias": alias},
        )

    def _get_or_create_test_run(
        self,
        test_run_type_id: int,
        start_time: datetime | None,
        end_time: datetime | None,
        jenkins_build_id: int | None,
        git_commit_hash: str,
        commit_time: datetime,
    ) -> int:
        # For test runs, we need special handling due to the enum cast
        with self._cursor() as cursor:
            select_query = sql.SQL(
                """
                SELECT id FROM {table}
                WHERE {test_run_type_id_col} = %s AND {git_commit_hash_col} = %s AND {git_branch_col} = %s
                """
            ).format(
                table=sql.Identifier("cmk_test_runs"),
                test_run_type_id_col=sql.Identifier("test_run_type_id"),
                git_commit_hash_col=sql.Identifier("git_commit_hash"),
                git_branch_col=sql.Identifier("git_branch"),
            )
            logger.debug("Executing select query:\n%s", select_query.as_string(cursor))
            try:
                cursor.execute(select_query, (test_run_type_id, git_commit_hash, git_branch))
            except PsycopgError as e:
                logger.error("Error executing select query: %s", e)
                raise
            if result := cursor.fetchone():
                return int(result[0])

            insert_query = sql.SQL(
                """
                INSERT INTO {table} ({columns})
                VALUES ({placeholders})
                RETURNING {returning_column}
                """
            ).format(
                table=sql.Identifier("cmk_test_runs"),
                columns=sql.SQL(", ").join(
                    [
                        sql.Identifier("test_run_type_id"),
                        sql.Identifier("start_time"),
                        sql.Identifier("end_time"),
                        sql.Identifier("jenkins_build_id"),
                        sql.Identifier("git_commit_hash"),
                        sql.Identifier("git_branch"),
                        sql.Identifier("commit_time"),
                    ]
                ),
                placeholders=sql.SQL(", ").join(
                    [
                        sql.Placeholder(),
                        sql.Placeholder(),
                        sql.Placeholder(),
                        sql.Placeholder(),
                        sql.Placeholder(),
                        sql.SQL("%s::cmk_git_branch_enum"),
                        sql.Placeholder(),
                    ]
                ),
                returning_column=sql.Identifier("id"),
            )

            logger.debug("Executing insert query:\n%s", insert_query.as_string(cursor))
            try:
                cursor.execute(
                    insert_query,
                    (
                        test_run_type_id,
                        start_time,
                        end_time,
                        jenkins_build_id,
                        git_commit_hash,
                        git_branch,
                        commit_time,
                    ),
                )
            except PsycopgError as e:
                logger.error("Error executing insert query: %s", e)
                raise
            result = cursor.fetchone()
            if not result:
                msg = f"Failed to create test run for commit: {git_commit_hash}"
                raise ValueError(msg)
            return int(result[0])

    def _upsert_record(
        self,
        table: str,
        conflict_columns: list[str],
        insert_values: dict[str, Any],
        update_values: dict[str, Any] | None = None,
    ) -> None:
        """
        Generic upsert (INSERT ... ON CONFLICT DO UPDATE) method.

        Args:
            table: Table name
            conflict_columns: Columns that define the conflict condition
            insert_values: Values for INSERT
            update_values: Values for UPDATE (defaults to same as insert_values)
        """
        update_values = update_values or insert_values

        with self._cursor() as cursor:
            columns = sql.SQL(", ").join(sql.Identifier(k) for k in insert_values.keys())
            placeholders = sql.SQL(", ").join([sql.Placeholder()] * len(insert_values))
            conflict_clause = sql.SQL(", ").join(sql.Identifier(col) for col in conflict_columns)
            update_clause = sql.SQL(", ").join(
                sql.SQL("{} = EXCLUDED.{}").format(sql.Identifier(k), sql.Identifier(k))
                for k in update_values.keys()
            )

            query = sql.SQL(
                """
                INSERT INTO {table} ({columns})
                VALUES ({placeholders})
                ON CONFLICT ({conflict_clause}) DO UPDATE SET {update_clause}
                """
            ).format(
                table=sql.Identifier(table),
                columns=columns,
                placeholders=placeholders,
                conflict_clause=conflict_clause,
                update_clause=update_clause,
            )
            logger.debug("Executing upsert query: %s", query.as_string(cursor))
            try:
                cursor.execute(query, list(insert_values.values()))
            except PsycopgError as e:
                logger.error("Error executing upsert query: %s", e)
                raise

    def insert_coverage_summary(
        self,
        makefile_target: str,
        alias: str,
        git_commit_hash: str,
        commit_time: datetime,
        coverage_stats: CoverageStats,
        start_time: datetime | None,
        end_time: datetime | None,
        jenkins_build_id: int | None = None,
    ) -> int:
        """
        Insert code coverage summary into the database.

        Args:
            makefile_target: Target name from check_mk/tests/Makefile
            alias: Descriptive code name of the test run type
            git_commit_hash: Git commit hash for the test run
            commit_time: Git committer time
            coverage_stats: Coverage statistics to insert
            start_time: Test run start time
            end_time: Test run end time
            jenkins_build_id: Optional Jenkins build ID

        Returns:
            Test run ID for the inserted coverage data
        """

        # Get or create test run type
        test_run_type_id = self._get_or_create_test_run_type(makefile_target, alias)

        # Get or create test run
        test_run_id = self._get_or_create_test_run(
            test_run_type_id=test_run_type_id,
            start_time=start_time,
            end_time=end_time,
            jenkins_build_id=jenkins_build_id,
            git_commit_hash=git_commit_hash,
            commit_time=commit_time,
        )

        # Insert or update coverage summary
        self._upsert_record(
            table="cmk_code_coverage_summary",
            conflict_columns=["test_run_id"],
            insert_values={
                "test_run_id": test_run_id,
                "lines_coverage_percent": coverage_stats["lines_coverage_percent"],
                "functions_coverage_percent": coverage_stats["functions_coverage_percent"],
                "covered_lines": coverage_stats["covered_lines"],
                "total_lines": coverage_stats["total_lines"],
                "covered_functions": coverage_stats["covered_functions"],
                "total_functions": coverage_stats["total_functions"],
            },
        )

        logger.info(
            "Inserted coverage summary: test_run_id=%s, lines=%.2f%%, functions=%.2f%%",
            test_run_id,
            coverage_stats["lines_coverage_percent"],
            coverage_stats["functions_coverage_percent"],
        )
        return test_run_id

    def insert_module_coverage(
        self,
        test_run_id: int,
        module_coverage_data: ModuleCoverageData,
    ) -> None:
        """
        Insert per-module coverage data into cmk_module_code_coverage table.

        Args:
            test_run_id: Test run ID to associate coverage data with
            module_coverage_data: List of module coverage dictionaries from CSV
        """
        module_count = 0
        for module_data in module_coverage_data:
            file_path = str(module_data["file_path"])

            if file_path == "TOTAL":
                continue  # Skip total row when inserting module data

            # Get or create source code module
            module_id = self._get_or_create_record(
                table="cmk_source_code_modules",
                select_conditions={"module_path": file_path},
                insert_values={
                    "module_name": Path(file_path).name,
                    "module_path": file_path,
                },
            )

            # Insert or update module coverage data
            self._upsert_record(
                table="cmk_module_code_coverage",
                conflict_columns=["test_run_id", "module_id"],
                insert_values={
                    "test_run_id": test_run_id,
                    "module_id": module_id,
                    "lines_coverage_percent": float(module_data["lines_coverage_percent"]),
                    "functions_coverage_percent": float(module_data["functions_coverage_percent"]),
                    "covered_lines": int(module_data["covered_lines"]),
                    "total_lines": int(module_data["total_lines"]),
                    "covered_functions": int(module_data["covered_functions"]),
                    "total_functions": int(module_data["total_functions"]),
                },
            )
            module_count += 1

        logger.info("Inserted coverage data for %d modules", module_count)


class CodeCoverageInsertArgs(argparse.Namespace):
    """Arguments for code coverage database insertion."""

    csv_file: Path
    makefile_target: str
    alias: str
    git_commit_hash: str
    commit_time: str
    jenkins_build_id: int | None
    dbname: str
    dbuser: str
    dbhost: str
    dbport: int
    sslmode: SslMode
    sslrootcert: Path | None
    sslcert: Path | None
    sslkey: Path | None
    include_module_data: bool
    log_level: str


def _sslmode_validator() -> Callable[[str], str]:
    """Create SSL mode validator function."""

    def validator(value: str) -> str:
        if value in get_args(SslMode):
            return value
        msg = f"Value '{value}' is not a valid sslmode!"
        raise argparse.ArgumentTypeError(msg)

    return validator


def _iso_time_validator(time_str: str) -> str:
    """Validate ISO format time string."""
    try:
        datetime.fromisoformat(time_str)
        return time_str
    except ValueError:
        raise argparse.ArgumentTypeError(
            f"Invalid ISO format: {time_str}. Expected format: YYYY-MM-DDTHH:MM:SS"
        )


def parse_args() -> CodeCoverageInsertArgs:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="Insert code coverage statistics from CSV into PostgreSQL database"
    )

    # Required arguments
    parser.add_argument(
        "--csv-file",
        type=Path,
        required=True,
        help="Path to the CSV coverage data file",
    )
    parser.add_argument(
        "--makefile-target",
        type=str,
        required=True,
        help="Target name from check_mk/tests/Makefile",
    )
    parser.add_argument(
        "--alias",
        type=str,
        required=True,
        help="Descriptive code name of the test run type",
    )
    parser.add_argument(
        "--git-commit-hash",
        type=str,
        required=True,
        help="Git commit hash of check_mk repository",
    )
    parser.add_argument(
        "--commit-time",
        type=_iso_time_validator,
        required=True,
        default=None,
        help="Git committer time in ISO format YYYY-MM-DDTHH:MM:SS",
    )

    # Optional arguments with environment variable defaults
    parser.add_argument(
        "--sslmode",
        type=_sslmode_validator(),
        default="allow",
        help="SSL mode for database connection (default: %(default)s)",
    )
    parser.add_argument(
        "--sslrootcert",
        type=Path,
        default=os.getenv("QA_ROOT_CERT"),
        help="Path to SSL root certificate, default passed by env QA_ROOT_CERT",
    )
    parser.add_argument(
        "--sslcert",
        type=Path,
        default=os.getenv("QA_POSTGRES_CERT"),
        help="Path to SSL certificate, default passed by env QA_POSTGRES_CERT",
    )
    parser.add_argument(
        "--sslkey",
        type=Path,
        default=os.getenv("QA_POSTGRES_KEY"),
        help="Path to SSL key, default passed by env QA_POSTGRES_KEY",
    )
    parser.add_argument(
        "--jenkins-build-id",
        type=int,
        default=os.getenv("BUILD_NUMBER"),
        help="Jenkins build ID (optional), no default",
    )
    parser.add_argument(
        "--dbport",
        type=int,
        default=int(os.getenv("POSTGRES_PORT", "5432")),
        help="Database port (optional, default passed by env POSTGRES_PORT)",
    )
    parser.add_argument(
        "--dbhost",
        type=str,
        default=os.getenv("POSTGRES_HOST"),
        help="Database host (optional, default passed by env POSTGRES_HOST)",
    )
    parser.add_argument(
        "--dbname",
        type=str,
        default=os.getenv("POSTGRES_DB"),
        help="Database name (optional, default passed by env POSTGRES_DB)",
    )
    parser.add_argument(
        "--dbuser",
        type=str,
        default=os.getenv("QA_POSTGRES_USER"),
        help="Database user (optional, default passed by env QA_POSTGRES_USER)",
    )

    # Additional options
    parser.add_argument(
        "--start-time",
        type=str,
        default=None,
        help="Test start time in ISO format YYYY-MM-DDTHH:MM:SS",
    )
    parser.add_argument(
        "--end-time",
        type=str,
        default=None,
        help="Test end time in ISO format YYYY-MM-DDTHH:MM:SS",
    )
    parser.add_argument(
        "--include-module-data",
        action="store_true",
        help="Include per-module coverage data in database",
    )
    parser.add_argument(
        "--log-level", type=str, default="INFO", help="Logging level (default: %(default)s)"
    )

    return parser.parse_args(namespace=CodeCoverageInsertArgs())


def _convert_csv_row(row: dict[str, str]) -> dict[str, str | int | float]:
    """Convert CSV row string values to appropriate types."""
    return {
        "file_path": row["file_path"],
        "lines_coverage_percent": float(row["lines_coverage_percent"]),
        "functions_coverage_percent": float(row["functions_coverage_percent"]),
        "covered_lines": int(row["covered_lines"]),
        "total_lines": int(row["total_lines"]),
        "covered_functions": int(row["covered_functions"]),
        "total_functions": int(row["total_functions"]),
    }


def _calculate_totals_from_modules(
    module_data: list[dict[str, str | int | float]],
) -> CoverageStats:
    """Calculate total coverage statistics from module data."""
    total_lines = sum(int(row["total_lines"]) for row in module_data)
    covered_lines = sum(int(row["covered_lines"]) for row in module_data)
    total_functions = sum(int(row["total_functions"]) for row in module_data)
    covered_functions = sum(int(row["covered_functions"]) for row in module_data)

    lines_coverage = 100.0 * covered_lines / total_lines if total_lines else 0
    functions_coverage = 100.0 * covered_functions / total_functions if total_functions else 0

    return CoverageStats(
        lines_coverage_percent=round(lines_coverage, 2),
        functions_coverage_percent=round(functions_coverage, 2),
        covered_lines=covered_lines,
        total_lines=total_lines,
        covered_functions=covered_functions,
        total_functions=total_functions,
    )


def read_csv_coverage_data(
    csv_file: Path,
) -> tuple[CoverageStats, list[dict[str, str | int | float]]]:
    """
    Read coverage data from CSV file.

    Returns:
        Tuple of (total_coverage_stats, all_module_data)
    """
    module_data = []
    total_stats = None

    with csv_file.open(encoding="utf-8") as csvfile:
        reader = csv.DictReader(csvfile)
        for row in reader:
            processed_row = _convert_csv_row(row)

            if row["file_path"] == "TOTAL":
                # Extract total statistics
                total_stats = CoverageStats(
                    lines_coverage_percent=float(processed_row["lines_coverage_percent"]),
                    functions_coverage_percent=float(processed_row["functions_coverage_percent"]),
                    covered_lines=int(processed_row["covered_lines"]),
                    total_lines=int(processed_row["total_lines"]),
                    covered_functions=int(processed_row["covered_functions"]),
                    total_functions=int(processed_row["total_functions"]),
                )
            else:
                module_data.append(processed_row)

    # Calculate totals from individual modules if TOTAL row not present
    if total_stats is None:
        total_stats = _calculate_totals_from_modules(module_data)

    return total_stats, module_data


def main() -> None:
    args = parse_args()
    logger.setLevel(args.log_level)

    if not args.csv_file.exists():
        logger.error("CSV file not found: %s", args.csv_file)
        return

    if args.sslrootcert is not None and args.sslcert is not None and args.sslkey is not None:
        _validate_ssl_files(args.sslrootcert, args.sslcert, args.sslkey)
    logger.info(
        "Starting code coverage insertion with args: %s",
        {
            "csv_file": str(args.csv_file),
            "target": args.makefile_target,
            "branch": git_branch,
            "commit": args.git_commit_hash[:11] + "..." if args.git_commit_hash else None,
        },
    )
    try:
        total_stats, module_data = _process_coverage_data(args.csv_file)
        _insert_coverage_data(args, total_stats, module_data)
        logger.info("Code coverage insertion completed successfully")
    except Exception as e:
        logger.error("Failed to process coverage data: %s", e)
        raise


def _validate_ssl_files(sslrootcert: Path, sslcert: Path, sslkey: Path) -> None:
    """Validate SSL certificate files exist and are readable."""
    for name, path in [
        ("root cert", sslrootcert),
        ("client cert", sslcert),
        ("client key", sslkey),
    ]:
        if not path.exists():
            msg = f"SSL {name} file not found: {path}"
            raise FileNotFoundError(msg)
        if not path.is_file():
            msg = f"SSL {name} path is not a file: {path}"
            raise ValueError(msg)


def _process_coverage_data(csv_file: Path) -> tuple[CoverageStats, ModuleCoverageData]:
    """Process CSV file and return coverage statistics."""
    logger.info("Reading CSV file: %s", csv_file)
    total_stats, module_data = read_csv_coverage_data(csv_file)

    logger.info(
        "Processed coverage data: %.2f%% lines, %.2f%% functions, %d modules",
        total_stats["lines_coverage_percent"],
        total_stats["functions_coverage_percent"],
        len(module_data),
    )
    return total_stats, module_data


def _insert_coverage_data(
    args: CodeCoverageInsertArgs, total_stats: CoverageStats, module_data: ModuleCoverageData
) -> None:
    """Insert coverage data into database."""
    with CodeCoverageDb(
        dbname=args.dbname,
        port=args.dbport,
        user=args.dbuser,
        host=args.dbhost,
        sslrootcert=args.sslrootcert,
        sslcert=args.sslcert,
        sslkey=args.sslkey,
        sslmode=args.sslmode,
    ) as db:
        if args.start_time is not None:
            args.start_time = datetime.fromisoformat(args.start_time)
        if args.end_time is not None:
            args.end_time = datetime.fromisoformat(args.end_time)

        test_run_id = db.insert_coverage_summary(
            makefile_target=args.makefile_target,
            alias=args.alias,
            git_commit_hash=args.git_commit_hash,
            commit_time=datetime.fromisoformat(args.commit_time),
            coverage_stats=total_stats,
            jenkins_build_id=args.jenkins_build_id,
            start_time=args.start_time,
            end_time=args.end_time,
        )

        if args.include_module_data and module_data:
            logger.info("Inserting per-module coverage data...")
            db.insert_module_coverage(test_run_id, module_data)


if __name__ == "__main__":
    main()
